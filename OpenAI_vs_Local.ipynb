{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GPT4ALL QA from docs:**\n",
    "**Para analizar grandes cantidades de datos el precio de OpenAI deja de ser trivial, por lo tanto se explora la posibilidad de usar modelos en local que realicen lo mismo pero con el nivel más parecido al SotA actual.\n",
    "Es por esto que se intenta usar [GPT4ALL](https://github.com/nomic-ai/gpt4all) y su implementación mediante librería [Langchain](https://python.langchain.com/en/latest/index.html#)**\n",
    "\n",
    "**Sin embargo, los embeddings de OPENAI siguen siendo baratos y efectivos, por lo que su uso sí tiene sentido**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import pypdf\n",
    "import langchain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "import pyllamacpp\n",
    "import tabula\n",
    "import openai\n",
    "\n",
    "api_key = json.load(open('./data/creds/gpt_id.json'))['api_key']\n",
    "openai.api_key = api_key\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones esenciales de procesamiento:\n",
    "def limpieza_texto(texto: str) -> str:\n",
    "    '''\n",
    "    Función para limpiar texto de pdfs.\n",
    "    Cambia saltos de línea, espacios en blanco y caracteres especiales.\n",
    "    '''\n",
    "    # Eliminamos espacios en blanco\n",
    "    #texto = re.sub(' +', ' ', texto)\n",
    "    # Eliminamos caracteres especiales [REVISAR]\n",
    "    #texto = re.sub('[^A-Za-z0-9]+', ' ', texto)\n",
    "    # Eliminamos saltos múltiples de línea\n",
    "    texto = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", texto)\n",
    "    texto = re.sub(r\"\\n\", \";\", texto)\n",
    "    return texto\n",
    "\n",
    "def tabla_a_texto(tabla):\n",
    "    '''\n",
    "    Función para convertir una tabla de pandas en un texto.\n",
    "    La idea es identificar los nombres de columna e índices correctos y\n",
    "    a partir de ahí generar un texto que pueda ser procesado por el modelo.\n",
    "    '''\n",
    "    tabla = tabla.copy()\n",
    "    \n",
    "    # Tamaño mínimo de tabla para que sea válida = 2x2\n",
    "    if sum(tabla.shape) < 4:\n",
    "        return ''\n",
    "    \n",
    "    # Lista de valores que consideramos NaN:\n",
    "    nan_equivalents = [np.NaN, np.nan,\n",
    "                       'nan', 'NaN', 'Nan', 'NAN', 'na', 'NA',\n",
    "                       'Unnamed:0', 'Unnamed: 0'\n",
    "                       '', '-', ' ', '  ', '   ']\n",
    "    \n",
    "    # Asumimos que el primer elemento es el título salvo si es NaN:\n",
    "    titulo = tabla.columns[0] if tabla.columns[0] not in nan_equivalents else ''\n",
    "    \n",
    "    # Asumimos que la primera columna es el índice y la eliminamos:\n",
    "    tabla.index = tabla[tabla.columns[0]].values\n",
    "    tabla.drop(columns=tabla.columns[0], inplace=True)\n",
    "\n",
    "    # Si las columnas tienen muchos 'Unnamed' suele ser porque hay\n",
    "    # varias líneas de texto. En ese caso, las juntamos en una sola:\n",
    "    if sum(['Unnamed' in i for i in tabla.columns]) > 2:\n",
    "        nueva_columna = [f'{tabla.columns[i]} {tabla.iloc[0,i]}'\n",
    "                         for i in range(len(tabla.columns))]\n",
    "        nueva_columna = [i.replace('Unnamed: ','') for i in nueva_columna]\n",
    "        tabla.columns = nueva_columna\n",
    "\n",
    "    \n",
    "    # Eliminamos las filas y columnas que no tienen datos:\n",
    "    tabla.replace(nan_equivalents, np.nan, inplace=True)\n",
    "    tabla.dropna(axis=0, how='all', inplace=True)\n",
    "    tabla.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    # Check si las columnas son años:\n",
    "    col_años = False\n",
    "    years_txt=[str(i) for i in range(2015,2022)]\n",
    "    years_int=[i for i in range(2015,2022)]\n",
    "    years = set(years_txt+years_int)\n",
    "    cruce = set(tabla.columns).intersection(set(years))\n",
    "    if len(cruce) > 0: col_años=True\n",
    "    \n",
    "    # Si no son años las columnas, buscamos filas que sean años:\n",
    "    contexto = None\n",
    "    if not col_años:\n",
    "        for i in tabla.iterrows():\n",
    "            #print(i[1].values)\n",
    "            try:\n",
    "                cruce = set(i[1].values).intersection(set(years))\n",
    "            except:\n",
    "                cruce=[]\n",
    "            if len(cruce)>0: # Si encontramos una fila con años:\n",
    "                # Asignamos los años a las columnas:\n",
    "                tabla.columns = i[1].values\n",
    "                try: \n",
    "                    contexto = i[1].name\n",
    "                except:\n",
    "                    contexto = None\n",
    "                # Drop de la fila:\n",
    "                tabla.drop(i[0], inplace=True)\n",
    "                break\n",
    "    # Los procesos anteriores pueden haber dejado filas vacías, las eliminamos:\n",
    "    tabla.replace(nan_equivalents, np.nan, inplace=True)\n",
    "    tabla.dropna(axis=0, how='all', inplace=True)\n",
    "    tabla.dropna(axis=1, how='all', inplace=True)\n",
    "    # Pasamos a texto:\n",
    "    texto = ''\n",
    "    for i in tabla.items():\n",
    "        txt = [f' {titulo} + {i[0]} + {x[0]} = {x[1]}; '\n",
    "            for x in list(i[1].items())]\n",
    "        add= ''.join(txt)\n",
    "        if contexto:\n",
    "            txt = [f' {titulo} + {contexto} + {i[0]} + {x[0]} = {x[1]}; '\n",
    "                for x in list(i[1].items())]\n",
    "            add = ''.join(txt)\n",
    "        add = add.replace('  ',' ').replace('\\n','; ').replace('  ','')\n",
    "        texto += f';  Tabla={titulo}: {add}'\n",
    "    return texto\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> list:\n",
    "    '''\n",
    "    Función para extraer texto de un pdf y limpiarlo.\n",
    "    Devuelve una lista de str, cada una es una página del pdf.\n",
    "    '''\n",
    "    # Abrimos el pdf\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf = pypdf.PdfReader(f)\n",
    "        # Obtenemos el número de páginas\n",
    "        num_pags = len(pdf.pages)\n",
    "        count = 0\n",
    "        text = []\n",
    "        # Iteramos sobre las páginas\n",
    "        for pag in pdf.pages:\n",
    "            count +=1\n",
    "            texto_pagina = pag.extract_text()\n",
    "            tablas = tabula.read_pdf(pdf_path, pages=count)\n",
    "            for tabla in tablas:\n",
    "                texto_pagina += f'; {tabla_a_texto(tabla=tabla)}; '\n",
    "            texto_pagina = limpieza_texto(texto_pagina)\n",
    "            text.append(texto_pagina)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos el PDF:\n",
    "resultado = extract_text_from_pdf('./data/rovi-sostenibilidad-2020.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un csv con 1 fila por página\n",
    "with open('lista_test_2.csv', 'w', newline='') as file:\n",
    "    \n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows([[str(i)] for i in resultado])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el csv como una lista (para comprobar que se ha guardado bien):\n",
    "csv_loaded = list(pd.read_csv('lista_test_2.csv', header=None)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTER ESTANDAR:\n",
    "splitter = langchain.text_splitter.RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function = len)\n",
    "\n",
    "x = splitter.create_documents(resultado, metadatas=[{'source': f'lista_test_2.csv pag{i}'} for i in list(range(len(resultado)))])\n",
    "\n",
    "loader = CSVLoader(file_path='lista_test_2.csv')\n",
    "\n",
    "documentos = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# SPLITTER POR TOKENS:\n",
    "import transformers\n",
    "tokenizador = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "gpt_splitter = langchain.text_splitter.CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizador, chunk_size=100, chunk_overlap=10)\n",
    "\n",
    "documentos = gpt_splitter.create_documents(\n",
    "    csv_loaded,\n",
    "    metadatas=[{'source': f'lista_test_2.csv pag.{i}'}\n",
    "               for i in list(range(len(csv_loaded)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT4All CHAIN for QA:\n",
    "gpt4all_path = './data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin'\n",
    "llm = langchain.llms.gpt4all.GPT4All(model=gpt4all_path,\n",
    "                                     n_threads=12)\n",
    "opai_llm = langchain.llms.openai.OpenAI()\n",
    "embedding = langchain.embeddings.openai.OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-06 19:38:17,563] {posthog.py:15} INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "[2023-04-06 19:38:17,564] {__init__.py:79} INFO - Running Chroma using direct local API.\n",
      "[2023-04-06 19:38:17,580] {__init__.py:48} WARNING - Using embedded DuckDB without persistence: data will be transient\n",
      "[2023-04-06 19:38:17,594] {ctypes.py:22} INFO - Successfully imported ClickHouse Connect C data optimizations\n",
      "[2023-04-06 19:38:17,595] {ctypes.py:31} INFO - Successfully import ClickHouse Connect C/Numpy optimizations\n",
      "[2023-04-06 19:38:17,603] {json_impl.py:45} INFO - Using python library for writing JSON byte strings\n"
     ]
    }
   ],
   "source": [
    "vector_store = langchain.vectorstores.Chroma.from_documents(documentos, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperador = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for StuffDocumentsChain\nreduce_k_below_max_tokens\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# OPENAI:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cadena_OAI \u001b[39m=\u001b[39m langchain\u001b[39m.\u001b[39;49mchains\u001b[39m.\u001b[39;49mquestion_answering\u001b[39m.\u001b[39;49mload_qa_chain(llm\u001b[39m=\u001b[39;49mopai_llm, reduce_k_below_max_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# GPT4ALL:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cadena_GPT4all \u001b[39m=\u001b[39m langchain\u001b[39m.\u001b[39mchains\u001b[39m.\u001b[39mquestion_answering\u001b[39m.\u001b[39mload_qa_chain(llm\u001b[39m=\u001b[39mllm)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\question_answering\\__init__.py:218\u001b[0m, in \u001b[0;36mload_qa_chain\u001b[1;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m chain_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loader_mapping:\n\u001b[0;32m    214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    215\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unsupported chain type: \u001b[39m\u001b[39m{\u001b[39;00mchain_type\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShould be one of \u001b[39m\u001b[39m{\u001b[39;00mloader_mapping\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m     )\n\u001b[1;32m--> 218\u001b[0m \u001b[39mreturn\u001b[39;00m loader_mapping[chain_type](\n\u001b[0;32m    219\u001b[0m     llm, verbose\u001b[39m=\u001b[39mverbose, callback_manager\u001b[39m=\u001b[39mcallback_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    220\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\question_answering\\__init__.py:67\u001b[0m, in \u001b[0;36m_load_stuff_chain\u001b[1;34m(llm, prompt, document_variable_name, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m llm_chain \u001b[39m=\u001b[39m LLMChain(\n\u001b[0;32m     64\u001b[0m     llm\u001b[39m=\u001b[39mllm, prompt\u001b[39m=\u001b[39m_prompt, verbose\u001b[39m=\u001b[39mverbose, callback_manager\u001b[39m=\u001b[39mcallback_manager\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[39m# TODO: document prompt\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m StuffDocumentsChain(\n\u001b[0;32m     68\u001b[0m     llm_chain\u001b[39m=\u001b[39mllm_chain,\n\u001b[0;32m     69\u001b[0m     document_variable_name\u001b[39m=\u001b[39mdocument_variable_name,\n\u001b[0;32m     70\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m     71\u001b[0m     callback_manager\u001b[39m=\u001b[39mcallback_manager,\n\u001b[0;32m     72\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     73\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for StuffDocumentsChain\nreduce_k_below_max_tokens\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "# OPENAI:\n",
    "cadena_OAI = langchain.chains.question_answering.load_qa_chain(llm=opai_llm, reduce_k_below_max_tokens=True)\n",
    "\n",
    "# GPT4ALL:\n",
    "cadena_GPT4all = langchain.chains.question_answering.load_qa_chain(llm=llm)\n",
    "\n",
    "# GPT4ALL Alternativa:\n",
    "esquema_pregunta = '''Question: {question}\n",
    "Answer: '''\n",
    "prompt = langchain.PromptTemplate(\n",
    "    template = esquema_pregunta,\n",
    "    input_variables=['question'],\n",
    ")\n",
    "cadena_alt = langchain.LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='are endangered. From a social point of view, the project will contribute to the ;sustainable development of rural producers and indigenous communities that ;live in nearby areas. The project has been certified by FSC (Forest Stewardship ;Council), CCB Gold Level (Climate, Community and Biodiversity) and VCS (Verified ;Carbon Standard).;ATMOSPHERIC EMISSIONS ;2020 2019 Variación Total ;Granada Madrid  ;& SSRR Alcalá de ;Henares Distr.  Granada Madrid  ;& SSRR Alcalá de ;Henares Distr.  Gr Mad  ;y SSRR AH Distr. ;Tonnes of Scope 1 ;CO2 emitted 805 1,494 2,663 836 468 1,399 2,880 1,262 72% 7% -8% -34%;Tonnes of Scope ;2 CO2 emitted 0 0 0 102 1,101 2,245 2,565 179 -100% -100% -100% -43%;Tonnes of Scope ;2 CO2 avoided (*) 1,193 2,198 2,999 96 0 0 0 0 - - - -;Tonnes CO2/ / ;million units. 0.004 22.58 104.85 42.30 0.003 27.54 137.86 71.42 38% -18% -24% -41%305-1;91; ;  Tabla=:  + 1 Granada + nan = Granada;+ 1 Granada + CO2 emitted = 805;+ 1 Granada + 2 CO2 emitted = 0;+ 1 Granada + 2 CO2 avoided (*) = 1,193;+ 1 Granada + million units. = 0.004; ;  Tabla=:  + Madrid & SSRR + nan = & SSRR;+ Madrid & SSRR + CO2 emitted = 1,494;+ Madrid & SSRR + 2 CO2 emitted = 0;+ Madrid & SSRR + 2 CO2 avoided (*) = 2,198;+ Madrid & SSRR + million units. = 22.58; ;  Tabla=:  + Alcalá de Henares + nan = Henares;+ Alcalá de Henares + CO2 emitted = 2,663;+ Alcalá de Henares + 2 CO2 emitted = 0;+ Alcalá de Henares + 2 CO2 avoided (*) = 2,999;+ Alcalá de Henares + million units. = 104.85; ;  Tabla=:  + 2 Distr. + nan = Distr.;+ 2 Distr. + CO2 emitted = 836;+ 2 Distr. + 2 CO2 emitted = 102;+ 2 Distr. + 2 CO2 avoided (*) = 96;+ 2 Distr. + million units. = 42.30; ;  Tabla=:  + 3 Granada + nan = Granada;+ 3 Granada + CO2 emitted = 468;+ 3 Granada + 2 CO2 emitted = 1,101;+ 3 Granada + 2 CO2 avoided (*) = 0;+ 3 Granada + million units. = 0.003; ;  Tabla=:  + Madrid.1 & SSRR + nan = & SSRR;+ Madrid.1 & SSRR + CO2 emitted = 1,399;+ Madrid.1 & SSRR + 2 CO2 emitted = 2,245;+ Madrid.1 & SSRR + 2 CO2 avoided (*) = 0;+ Madrid.1 & SSRR + million units. = 27.54; ;  Tabla=:  + Alcalá de.1 Henares + nan = Henares;+ Alcalá de.1 Henares + CO2 emitted = 2,880;+ Alcalá de.1 Henares + 2 CO2 emitted = 2,565;+ Alcalá de.1 Henares + 2 CO2 avoided (*) = 0;+ Alcalá de.1 Henares + million units. = 137.86; ;  Tabla=:  + 4 Distr. + nan = Distr.;+ 4 Distr. + CO2 emitted = 1,262;+ 4 Distr. + 2 CO2 emitted = 179;+ 4 Distr. + 2 CO2 avoided (*) = 0;+ 4 Distr. + million units. = 71.42; ;  Tabla=:  + 5 Gr + nan = Gr;+ 5 Gr + CO2 emitted = 72%;+ 5 Gr + 2 CO2 emitted = -100%;+ 5 Gr + 2 CO2 avoided (*) = nan;+ 5 Gr + million units. = 38%; ;  Tabla=:  + Mad y SSRR + nan = y SSRR;+ Mad y SSRR + CO2 emitted = 7%;+ Mad y SSRR + 2 CO2 emitted = -100%;+ Mad y SSRR + 2 CO2 avoided (*) = nan;+ Mad y SSRR + million units. = -18%; ;  Tabla=:  + 6 AH + nan = AH;+ 6 AH + CO2 emitted = -8%;+ 6 AH + 2 CO2 emitted = -100%;+ 6 AH + 2 CO2 avoided (*) = nan;+ 6 AH + million units. = -24%; ;  Tabla=:  + 7 Distr. + nan = Distr.;+ 7 Distr. + CO2 emitted = -34%;+ 7 Distr. + 2 CO2 emitted = -43%;+ 7 Distr. + 2 CO2 avoided (*) = nan;+ 7 Distr. + million units. = -41%; ;', metadata={'source': 'lista_test_2.csv pag.90'}), Document(page_content='NATURAL RESOURCE CONSUMPTION  ;2020 2019 Total variation ;NATURAL ;RESOURCE ;CONSUMPTION ;(*) Granada Madrid  ;& SSRR Alcalá de ;Henares Distr.  Granada Madrid  ;& SSRR Alcalá de ;Henares Distr.  Gr Mad  ;y SSRR AH Distr. ;m3 water ;consumed 28,555 55,369 58,641 7,606 24,026 58,931 63,114 2,561 19% -6% -7% 197% ;m3 water / ;million units ;produced 0.1 338.6 1,085.9 311.2 0.0 445.4 1,597.8 126.9 29% 24% -32% 145%;;In addition to the figure reported, in 2020 1,063 m3 of well water was consumed for watering ;at the Alcalá de Henares plant. 100% of the rest of the water supply from the mains. The ;increase in water consumption in the Distribution area in 2020 in comparison to 2019 was ;due the fact that, in 2020, direct readings were taken in the equipment every month of the ;year. In 2019, however, readings were only taken of three months’ consumption.;;EMISSIONS AND REDUCTION IN CARBON FOOTPRINT;At ROVI, as a contribution to the fight against climate change, not only is electricity taken ;into account, but the CO2 emissions caused by the consumption of natural gas and diesel ;fuel, derived from electricity and automobiles, are measured, as well as other substances ;that act to destroy the ozone layer. ROVI’s greenhouse gas emissions have always been ;insignificant and very much below the legally-established levels.;In 2020, as mentioned above, ROVI developed a new Climate Change Policy and, ;additionally, undertook a project to reduce CO2 emissions, Zero Emissions, during which ;the following initiatives were taken:;• A contract was signed for 100% of the electricity used at the industrial plants to come ;from renewable sources.;• Compensation of the rest of the tonnes emitted by VER (Voluntary Emission ;Reduction) projects. Specifically:;• GHANA COOKSTOVE. The Gyapa Cookstove cooks food faster and needs less fuel. ;Thus, not only does it reduce carbon emissions, but it also reduces exposure to ;toxic fumes. The key benefits are: reduction in fuel costs, improvement in health, ;deceleration in deforestation, generation of employment and reduction in ;carbon.;• Madre de Dios Amazon REDD Project. The project is located in the region ;belonging to the Vilacamba-Amoboró Ecological Corridor, one of the critical ;points in biodiversity. The jungle where the project is located is very importance ;in terms of the conservation of biodiversity, since it provides a habitat to four ;tropical jungle wildlife species that are in danger of extinction and eleven that 303-1;90; ;  Tabla=NATURAL:  NATURAL + 0 nan + CONSUMPTION = nan; NATURAL + 0 nan + (*) = Granada; NATURAL + 0 nan + consumed = 28,555; NATURAL + 0 nan + produced = 0.1; ;  Tabla=NATURAL:  NATURAL + 1 nan + CONSUMPTION = Madrid; NATURAL + 1 nan + (*) = & SSRR; NATURAL + 1 nan + consumed = 55,369; NATURAL + 1 nan + produced = 338.6; ;  Tabla=NATURAL:  NATURAL + 2 nan + CONSUMPTION = Alcalá de; NATURAL + 2 nan + (*) = Henares; NATURAL + 2 nan + consumed = 58,641; NATURAL + 2 nan + produced = 1,085.9; ;  Tabla=NATURAL:  NATURAL + 3 nan + CONSUMPTION = nan; NATURAL + 3 nan + (*) = Distr.; NATURAL + 3 nan + consumed = 7,606; NATURAL + 3 nan + produced = 311.2; ;  Tabla=NATURAL:  NATURAL + 4 nan + CONSUMPTION = nan; NATURAL + 4 nan + (*) = Granada; NATURAL + 4 nan + consumed = 24,026; NATURAL + 4 nan + produced = 0.0; ;  Tabla=NATURAL:  NATURAL + 5 nan + CONSUMPTION = Madrid; NATURAL + 5 nan + (*) = & SSRR; NATURAL + 5 nan + consumed = 58,931; NATURAL + 5 nan + produced = 445.4; ;  Tabla=NATURAL:  NATURAL + 6 nan + CONSUMPTION = Alcalá de; NATURAL + 6 nan + (*) = Henares; NATURAL + 6 nan + consumed = 63,114; NATURAL + 6 nan + produced = 1,597.8; ;  Tabla=NATURAL:  NATURAL + 7 nan + CONSUMPTION = nan; NATURAL + 7 nan + (*) = Distr.; NATURAL + 7 nan + consumed = 2,561; NATURAL + 7 nan + produced = 126.9; ;  Tabla=NATURAL:  NATURAL + 8 nan + CONSUMPTION = nan; NATURAL + 8 nan + (*) = Gr; NATURAL + 8 nan + consumed = 19%; NATURAL + 8 nan + produced = 29%; ;  Tabla=NATURAL:  NATURAL + 9 nan + CONSUMPTION = Mad; NATURAL + 9 nan + (*) = y SSRR; NATURAL + 9 nan + consumed = -6%; NATURAL + 9 nan + produced = 24%; ;  Tabla=NATURAL:  NATURAL + 10 nan + CONSUMPTION = nan; NATURAL + 10 nan + (*) = AH; NATURAL + 10 nan + consumed = -7%; NATURAL + 10 nan + produced = -32%; ;  Tabla=NATURAL:  NATURAL + 11 nan + CONSUMPTION = nan; NATURAL + 11 nan + (*) = Distr.; NATURAL + 11 nan + consumed = 197%; NATURAL + 11 nan + produced = 145%; ;', metadata={'source': 'lista_test_2.csv pag.89'}), Document(page_content='ID. INDICATOR Report page;GRI 300 ENVIRONMENTAL TOPICS;103-1 Explanation of the material topic and its boundary 21;103-2 The management approach and its components 21;103-3 Evaluation of the management approach 21;301-1 Materials used by weight or volume 88;302-1 Energy consumption within the organisation 89;303-1 Water withdrawal by source 90;305-1 Direct (Scope 1) GHG emissions 91;GRI 400 SOCIAL TOPICS;103-1 Explanation of the material topic and its boundary 21;103-2 The management approach and its components 21;103-3 Evaluation of the management approach 21;401-2Benefits provided to full-time employees that are not provided to tempo -;rary or part-time employees55;403-1Worker representation in formal joint management worker health and ;safety committees63;404-1 Average hours of training per year per employee 60, 61;96', metadata={'source': 'lista_test_2.csv pag.95'}), Document(page_content='Regarding energy and natural resource consumption, water, electricity and gas indicators ;are checked and reported on a monthly basis, analysing any deviations. Likewise, in the ;Distribution business, a provider of 100% renewable energy is used.;ENERGY CONSUMPTION ;2020 2019 Total variation ;(*) ENERGY ;CONSUMPTION Granada Madrid  ;& SSRR Alcalá de ;Henares Distr.  Granada Madrid  ;& SSRR Alcalá de ;Henares Distr.  Gr Mad  ;y SSRR AH Distr. ;kWh electricity ;consumed 3,848,018 7,091,109 9,673,660 637,543 3,822,809 7,795,638 8,906,808 623,206 1% -9% 9 2 ;kWh electricity ;/ million units ;produced 8 43,365 179,142 26,089 7 58,924 225,489 30,889  9% -26% -21% -16% ;kWh natural gas ;consumed 4,405,540 7,570,552 14,549,428 0 2,285,101 6,836,948 14,048,975 0 93% 11% 4% - ;kWh natural gas ;/ million units ;produced 9 46,297 269,434 0 4 51,678 355,670 0 109% -10% -24% - ;Litres vehicle fuel 1,000 40,498 5,231 291,520 300 0 2,175 485,185 233% - 140% -40%;Due to a change in the calculation of the kWh of electricity consumed in the Distribution ;area, the 2019 Distribution figures shown above have been changed slightly from those ;reported in the 2019 Statement of Non-financial Information, in order to allow a comparison ;of this indicator.;The increase in the indicator of natural gas consumed at the Granada plant in 2020 in ;comparison with 2019 was due to the fact that, in June 2020, new facilities that required ;natural gas were put into operation. In addition, several incidents were detected that, to ;a lesser extent, led to an increase in gas consumption unrelated to the consumption in ;production. These incidents were duly solved.302-1;89; ;  Tabla=(*) ENERGY:  (*) ENERGY + 0 Granada + CONSUMPTION = Granada; (*) ENERGY + 0 Granada + consumed = 3,848,018; (*) ENERGY + 0 Granada + produced = 8; (*) ENERGY + 0 Granada + consumed = 4,405,540; (*) ENERGY + 0 Granada + produced = 9; (*) ENERGY + 0 Granada + Litres vehicle fuel = 1,000; ;  Tabla=(*) ENERGY:  (*) ENERGY + Madrid & SSRR + CONSUMPTION = & SSRR; (*) ENERGY + Madrid & SSRR + consumed = 7,091,109; (*) ENERGY + Madrid & SSRR + produced = 43,365; (*) ENERGY + Madrid & SSRR + consumed = 7,570,552; (*) ENERGY + Madrid & SSRR + produced = 46,297; (*) ENERGY + Madrid & SSRR + Litres vehicle fuel = 40,498; ;  Tabla=(*) ENERGY:  (*) ENERGY + Alcalá de Henares + CONSUMPTION = Henares; (*) ENERGY + Alcalá de Henares + consumed = 9,673,660; (*) ENERGY + Alcalá de Henares + produced = 179,142; (*) ENERGY + Alcalá de Henares + consumed = 14,549,428; (*) ENERGY + Alcalá de Henares + produced = 269,434; (*) ENERGY + Alcalá de Henares + Litres vehicle fuel = 5,231; ;  Tabla=(*) ENERGY:  (*) ENERGY + 1 Distr. + CONSUMPTION = Distr.; (*) ENERGY + 1 Distr. + consumed = 637,543; (*) ENERGY + 1 Distr. + produced = 26,089; (*) ENERGY + 1 Distr. + consumed = 0; (*) ENERGY + 1 Distr. + produced = 0; (*) ENERGY + 1 Distr. + Litres vehicle fuel = 291,520; ;  Tabla=(*) ENERGY:  (*) ENERGY + 2 Granada + CONSUMPTION = Granada; (*) ENERGY + 2 Granada + consumed = 3,822,809; (*) ENERGY + 2 Granada + produced = 7; (*) ENERGY + 2 Granada + consumed = 2,285,101; (*) ENERGY + 2 Granada + produced = 4; (*) ENERGY + 2 Granada + Litres vehicle fuel = 300; ;  Tabla=(*) ENERGY:  (*) ENERGY + Madrid.1 & SSRR + CONSUMPTION = & SSRR; (*) ENERGY + Madrid.1 & SSRR + consumed = 7,795,638; (*) ENERGY + Madrid.1 & SSRR + produced = 58,924; (*) ENERGY + Madrid.1 & SSRR + consumed = 6,836,948; (*) ENERGY + Madrid.1 & SSRR + produced = 51,678; (*) ENERGY + Madrid.1 & SSRR + Litres vehicle fuel = 0; ;  Tabla=(*) ENERGY:  (*) ENERGY + Alcalá de.1 Henares + CONSUMPTION = Henares; (*) ENERGY + Alcalá de.1 Henares + consumed = 8,906,808; (*) ENERGY + Alcalá de.1 Henares + produced = 225,489; (*) ENERGY + Alcalá de.1 Henares + consumed = 14,048,975; (*) ENERGY + Alcalá de.1 Henares + produced = 355,670; (*) ENERGY + Alcalá de.1 Henares + Litres vehicle fuel = 2,175; ;  Tabla=(*) ENERGY:  (*) ENERGY + 3 Distr. + CONSUMPTION = Distr.; (*) ENERGY + 3 Distr. + consumed = 623,206; (*) ENERGY + 3 Distr. + produced = 30,889; (*) ENERGY + 3 Distr. + consumed = 0; (*) ENERGY + 3 Distr. + produced = 0; (*) ENERGY + 3 Distr. + Litres vehicle fuel = 485,185; ;  Tabla=(*) ENERGY:  (*) ENERGY + 4 Gr + CONSUMPTION = Gr; (*) ENERGY + 4 Gr + consumed = 1%; (*) ENERGY + 4 Gr + produced = 9%; (*) ENERGY + 4 Gr + consumed = 93%; (*) ENERGY + 4 Gr + produced = 109%; (*) ENERGY + 4 Gr + Litres vehicle fuel = 233%; ;  Tabla=(*) ENERGY:  (*) ENERGY + Mad y SSRR + CONSUMPTION = y SSRR; (*) ENERGY + Mad y SSRR + consumed = -9%; (*) ENERGY + Mad y SSRR + produced = -26%; (*) ENERGY + Mad y SSRR + consumed = 11%; (*) ENERGY + Mad y SSRR + produced = -10%; (*) ENERGY + Mad y SSRR + Litres vehicle fuel = nan; ;  Tabla=(*) ENERGY:  (*) ENERGY + 5 AH + CONSUMPTION = AH; (*) ENERGY + 5 AH + consumed = 9; (*) ENERGY + 5 AH + produced = -21%; (*) ENERGY + 5 AH + consumed = 4%; (*) ENERGY + 5 AH + produced = -24%; (*) ENERGY + 5 AH + Litres vehicle fuel = 140%; ;  Tabla=(*) ENERGY:  (*) ENERGY + 6 Distr. + CONSUMPTION = Distr.; (*) ENERGY + 6 Distr. + consumed = 2; (*) ENERGY + 6 Distr. + produced = -16%; (*) ENERGY + 6 Distr. + consumed = nan; (*) ENERGY + 6 Distr. + produced = nan; (*) ENERGY + 6 Distr. + Litres vehicle fuel = -40%; ;', metadata={'source': 'lista_test_2.csv pag.88'})]\n"
     ]
    }
   ],
   "source": [
    "pregunta = 'How much CO2 was emitted in total according to this document?'\n",
    "similares = vector_store.similarity_search(pregunta, include_metadata=True, top_k=4)\n",
    "print(similares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-06 19:38:39,377] {util.py:67} INFO - error_code=None error_message=\"This model's maximum context length is 4097 tokens, however you requested 5022 tokens (4766 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 5022 tokens (4766 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# OPENAI:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cadena_OAI\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m      3\u001b[0m     input_documents \u001b[39m=\u001b[39;49m similares,\n\u001b[0;32m      4\u001b[0m     question \u001b[39m=\u001b[39;49m pregunta)  \n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:216\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    218\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but not both. Got args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:56\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m     55\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[1;32m---> 56\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_docs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mother_keys)\n\u001b[0;32m     57\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[0;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:89\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs), {}\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:151\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    138\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:57\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:118\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[0;32m    117\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:62\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list)\n\u001b[1;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(prompts, stop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:107\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m, prompts: List[PromptValue], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    106\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:140\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:137\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\openai.py:281\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    279\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39m, prompt\u001b[39m=\u001b[39m_prompts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    282\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[0;32m    284\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\openai.py:99\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     97\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\openai.py:97\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\openai\\api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    624\u001b[0m         ),\n\u001b[0;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\openai\\api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 5022 tokens (4766 in your prompt; 256 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "# OPENAI:\n",
    "cadena_OAI.run(\n",
    "    input_documents = similares,\n",
    "    question = pregunta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT4ALL:\n",
    "cadena_GPT4all.run(\n",
    "    input_documents = similares,\n",
    "    question = pregunta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Question: How much CO2 was emitted in total according to this document?\\nAnswer: 3.8 trillion metric tons of carbon dioxide were released into the atmosphere from human activities since preindustrial times, contributing greatly to climate change and global warming'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT4ALL con Cadena Alternativa:\n",
    "cadena_alt.run(\n",
    "    input_documents = similares,\n",
    "    question = pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='REPORT;20;20: 98www.rovi.es', metadata={'source': 'lista_test_2.csv', 'row': 96}),\n",
       " Document(page_content='REPORT;20;20: SHAREHOLDER COMPOSITION;63.11%;Norbel Inversores, S.L.;5.57%;Indumenta Pueri, S.L.;3.043%;T.Rowe Price International Funds, Inc;3.005%;Wellington Management Group, LLP;25.275%;Other;7', metadata={'source': 'lista_test_2.csv', 'row': 5}),\n",
       " Document(page_content='REPORT;20;20: –Profarma;Each year, in the Plan Profarma, the Ministry of Industry, Tourism and Trade and the Ministry ;of Health, Social Services and Equality classify the pharmaceutical Companies in accordance ;with their contribution to the Spanish industrial fabric, taking their investment in technology, ;new manufacturing plants, research efforts, etc. as a reference. In February 2020, the results ;of Plan Profarma 2019 were issued and ROVI obtained the classification of Excellent for the ;fourteenth consecutive year. ;KEY FIGURES;(million euros) 2020 2019 2018 2017;Total revenue 421.1 382.5  304.8 277.4;EBITDA 94.2 60.9 29.5 29.9;Net financial debt 19.8 15.9 -62.8 1.1;Employees 1.419 1.310 1.224 1.191102-7;14; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2020.0 + Total revenue = 421.1; KEY FIGURES + (million euros) + 2020.0 + EBITDA = 94.2; KEY FIGURES + (million euros) + 2020.0 + Net financial debt = 19.8; KEY FIGURES + (million euros) + 2020.0 + Employees = 1.419; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2019.0 + Total revenue = 382.5; KEY FIGURES + (million euros) + 2019.0 + EBITDA = 60.9; KEY FIGURES + (million euros) + 2019.0 + Net financial debt = 15.9; KEY FIGURES + (million euros) + 2019.0 + Employees = 1.31; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2018.0 + Total revenue = 304.8; KEY FIGURES + (million euros) + 2018.0 + EBITDA = 29.5; KEY FIGURES + (million euros) + 2018.0 + Net financial debt = -62.8; KEY FIGURES + (million euros) + 2018.0 + Employees = 1.224; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2017.0 + Total revenue = 277.4; KEY FIGURES + (million euros) + 2017.0 + EBITDA = 29.9; KEY FIGURES + (million euros) + 2017.0 + Net financial debt = 1.1; KEY FIGURES + (million euros) + 2017.0 + Employees = 1.191; ;', metadata={'source': 'lista_test_2.csv', 'row': 12}),\n",
       " Document(page_content='REPORT;20;20: Shareholders have the possibility of receiving ROVI’s financial information automatically ;through an e-mail alert system.  Furthermore, the group provides regular, prompt and ;relevant information on the company, such as presentations and legal documents on ;economic and financial aspects and corporate governance, which may be consulted in the ;Investors and Shareholders section of the corporate website www.rovi.es.;Coinciding with its General Shareholders’ Meeting, ROVI prepares an Integrated Report ;in which it summarises the strategic lines of its work and the activities carried out in ;the preceding year. This document forms part of the Informe Reporta, prepared by the ;consulting company Deva, which rates the reports published by the companies listed on the ;General Index of the Madrid Stock Exchange (IGBM) in accordance with the quality of the ;information they provide. In the 2020 edition of Informe Reporta, ROVI was in 22nd place of ;this ranking, which is formed by 120 companies, maintaining the same position as it held in ;2019.; –Customers;ROVI has a query channel for information requests from both international partners and ;direct customers, patients and professionals: www.bemimed.com.;In the event of a complaint, the company opens an enquiry immediately in order to identify ;the cause and prevent any repetition. Furthermore, there is a contact telephone number and ;the e-mail rovi@rovi.es where queries and complaints may be made.; –Society and environment;As a catalyst in its socioeconomic surroundings and aware of the impact of its activity on ;the environment, ROVI is committed, as an integral part of its day-to-day activity, to the ;protection of the environment, as well as to improving the situation of society in general and ;the different geographical areas  all over the world where it is present with its product or ;plants.;The company’s environmental policy is based on commitments to continuing improvement ;of products and processes, while, at the same time, complying with both legal requirements ;and additional voluntary requirements. In relation to environmental queries, ROVI has a ;corporate procedure through which it manages communications (queries, complaints, etc.) ;related to the environment and occupational health and safety. On the corporate website ;(www.rovi.es), the quality, environmental and occupational health and safety certifications ;held by group companies are available to the public. ;Over recent years, the company has carried out intensive activity to support research and ;promote prevention and knowledge of certain diseases. ROVI allocates part of its resources ;to driving medical and healthcare knowledge forward through contributions to different ;projects and co-operation with higher-education entities, with which it also works to help ;young professionals enter the workplace through scholarships and training. ;27', metadata={'source': 'lista_test_2.csv', 'row': 25})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pregunta = '¿De qué empresa es este informe?'\n",
    "similares = recuperador.get_relevant_documents(pregunta)\n",
    "cadena.run(input_documents = similares, question = pregunta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Could not load Llama model from path: ./data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\embeddings\\llamacpp.py:76\u001b[0m, in \u001b[0;36mLlamaCppEmbeddings.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mllama_cpp\u001b[39;00m \u001b[39mimport\u001b[39;00m Llama\n\u001b[0;32m     78\u001b[0m     values[\u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m Llama(\n\u001b[0;32m     79\u001b[0m         model_path\u001b[39m=\u001b[39mmodel_path,\n\u001b[0;32m     80\u001b[0m         n_ctx\u001b[39m=\u001b[39mn_ctx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m         embedding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     90\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\llama_cpp\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mllama_cpp\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mllama\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\llama_cpp\\llama_cpp.py:46\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Load the library\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m _lib \u001b[39m=\u001b[39m _load_shared_library(_lib_base_name)\n\u001b[0;32m     48\u001b[0m \u001b[39m# C types\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\llama_cpp\\llama_cpp.py:40\u001b[0m, in \u001b[0;36m_load_shared_library\u001b[1;34m(lib_base_name)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to load shared library \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m_lib_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShared library with base name \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlib_base_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Shared library with base name 'llama' not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m \u001b[39mimport\u001b[39;00m LlamaCppEmbeddings\n\u001b[1;32m----> 2\u001b[0m LlamaCppEmbeddings(model_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pydantic\\main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pydantic\\main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\embeddings\\llamacpp.py:98\u001b[0m, in \u001b[0;36mLlamaCppEmbeddings.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import llama-cpp-python library. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install the llama-cpp-python library to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39muse this embedding model: pip install llama-cpp-python\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNameError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load Llama model from path: \u001b[39m\u001b[39m{\u001b[39;00mmodel_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[1;31mNameError\u001b[0m: Could not load Llama model from path: ./data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "LlamaCppEmbeddings(model_path='./data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdelt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
