{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GPT4ALL QA from docs:**\n",
    "**Para analizar grandes cantidades de datos el precio de OpenAI deja de ser trivial, por lo tanto se explora la posibilidad de usar modelos en local que realicen lo mismo pero con el nivel más parecido al SotA actual.\n",
    "Es por esto que se intenta usar [GPT4ALL](https://github.com/nomic-ai/gpt4all) y su implementación mediante librería [Langchain](https://python.langchain.com/en/latest/index.html#)**\n",
    "\n",
    "**Sin embargo, los embeddings de OPENAI siguen siendo baratos y efectivos, por lo que su uso sí tiene sentido**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import pypdf\n",
    "import langchain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "import pyllamacpp\n",
    "import tabula\n",
    "import openai\n",
    "\n",
    "api_key = json.load(open('./data/creds/gpt_id.json'))['api_key']\n",
    "openai.api_key = api_key\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones esenciales de procesamiento:\n",
    "def limpieza_texto(texto: str) -> str:\n",
    "    '''\n",
    "    Función para limpiar texto de pdfs.\n",
    "    Cambia saltos de línea, espacios en blanco y caracteres especiales.\n",
    "    '''\n",
    "    # Eliminamos espacios en blanco\n",
    "    #texto = re.sub(' +', ' ', texto)\n",
    "    # Eliminamos caracteres especiales [REVISAR]\n",
    "    #texto = re.sub('[^A-Za-z0-9]+', ' ', texto)\n",
    "    # Eliminamos saltos múltiples de línea\n",
    "    texto = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", texto)\n",
    "    texto = re.sub(r\"\\n\", \";\", texto)\n",
    "    return texto\n",
    "\n",
    "def tabla_a_texto(tabla):\n",
    "    '''\n",
    "    Función para convertir una tabla de pandas en un texto.\n",
    "    La idea es identificar los nombres de columna e índices correctos y\n",
    "    a partir de ahí generar un texto que pueda ser procesado por el modelo.\n",
    "    '''\n",
    "    tabla = tabla.copy()\n",
    "    \n",
    "    # Tamaño mínimo de tabla para que sea válida = 2x2\n",
    "    if sum(tabla.shape) < 4:\n",
    "        return ''\n",
    "    \n",
    "    # Lista de valores que consideramos NaN:\n",
    "    nan_equivalents = [np.NaN, np.nan,\n",
    "                       'nan', 'NaN', 'Nan', 'NAN', 'na', 'NA',\n",
    "                       'Unnamed:0', 'Unnamed: 0'\n",
    "                       '', '-', ' ', '  ', '   ']\n",
    "    \n",
    "    # Asumimos que el primer elemento es el título salvo si es NaN:\n",
    "    titulo = tabla.columns[0] if tabla.columns[0] not in nan_equivalents else ''\n",
    "    \n",
    "    # Asumimos que la primera columna es el índice y la eliminamos:\n",
    "    tabla.index = tabla[tabla.columns[0]].values\n",
    "    tabla.drop(columns=tabla.columns[0], inplace=True)\n",
    "\n",
    "    # Si las columnas tienen muchos 'Unnamed' suele ser porque hay\n",
    "    # varias líneas de texto. En ese caso, las juntamos en una sola:\n",
    "    if sum(['Unnamed' in i for i in tabla.columns]) > 2:\n",
    "        nueva_columna = [f'{tabla.columns[i]} {tabla.iloc[0,i]}'\n",
    "                         for i in range(len(tabla.columns))]\n",
    "        nueva_columna = [i.replace('Unnamed: ','') for i in nueva_columna]\n",
    "        tabla.columns = nueva_columna\n",
    "\n",
    "    \n",
    "    # Eliminamos las filas y columnas que no tienen datos:\n",
    "    tabla.replace(nan_equivalents, np.nan, inplace=True)\n",
    "    tabla.dropna(axis=0, how='all', inplace=True)\n",
    "    tabla.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    # Check si las columnas son años:\n",
    "    col_años = False\n",
    "    years_txt=[str(i) for i in range(2015,2022)]\n",
    "    years_int=[i for i in range(2015,2022)]\n",
    "    years = set(years_txt+years_int)\n",
    "    cruce = set(tabla.columns).intersection(set(years))\n",
    "    if len(cruce) > 0: col_años=True\n",
    "    \n",
    "    # Si no son años las columnas, buscamos filas que sean años:\n",
    "    contexto = None\n",
    "    if not col_años:\n",
    "        for i in tabla.iterrows():\n",
    "            #print(i[1].values)\n",
    "            try:\n",
    "                cruce = set(i[1].values).intersection(set(years))\n",
    "            except:\n",
    "                cruce=[]\n",
    "            if len(cruce)>0: # Si encontramos una fila con años:\n",
    "                # Asignamos los años a las columnas:\n",
    "                tabla.columns = i[1].values\n",
    "                try: \n",
    "                    contexto = i[1].name\n",
    "                except:\n",
    "                    contexto = None\n",
    "                # Drop de la fila:\n",
    "                tabla.drop(i[0], inplace=True)\n",
    "                break\n",
    "    # Los procesos anteriores pueden haber dejado filas vacías, las eliminamos:\n",
    "    tabla.replace(nan_equivalents, np.nan, inplace=True)\n",
    "    tabla.dropna(axis=0, how='all', inplace=True)\n",
    "    tabla.dropna(axis=1, how='all', inplace=True)\n",
    "    # Pasamos a texto:\n",
    "    texto = ''\n",
    "    for i in tabla.items():\n",
    "        txt = [f' {titulo} + {i[0]} + {x[0]} = {x[1]}; '\n",
    "            for x in list(i[1].items())]\n",
    "        add= ''.join(txt)\n",
    "        if contexto:\n",
    "            txt = [f' {titulo} + {contexto} + {i[0]} + {x[0]} = {x[1]}; '\n",
    "                for x in list(i[1].items())]\n",
    "            add = ''.join(txt)\n",
    "        add = add.replace('  ',' ').replace('\\n','; ').replace('  ','')\n",
    "        texto += f';  Tabla={titulo}: {add}'\n",
    "    return texto\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> list:\n",
    "    '''\n",
    "    Función para extraer texto de un pdf y limpiarlo.\n",
    "    Devuelve una lista de str, cada una es una página del pdf.\n",
    "    '''\n",
    "    # Abrimos el pdf\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf = pypdf.PdfReader(f)\n",
    "        # Obtenemos el número de páginas\n",
    "        num_pags = len(pdf.pages)\n",
    "        count = 0\n",
    "        text = []\n",
    "        # Iteramos sobre las páginas\n",
    "        for pag in pdf.pages:\n",
    "            count +=1\n",
    "            texto_pagina = pag.extract_text()\n",
    "            tablas = tabula.read_pdf(pdf_path, pages=count)\n",
    "            for tabla in tablas:\n",
    "                texto_pagina += f'; {tabla_a_texto(tabla=tabla)}; '\n",
    "            texto_pagina = limpieza_texto(texto_pagina)\n",
    "            text.append(texto_pagina)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos el PDF:\n",
    "resultado = extract_text_from_pdf('./data/rovi-sostenibilidad-2020.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un csv con 1 fila por página\n",
    "with open('lista_test_2.csv', 'w', newline='') as file:\n",
    "    \n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows([[str(i)] for i in resultado])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el csv como una lista (para comprobar que se ha guardado bien):\n",
    "csv_loaded = list(pd.read_csv('lista_test_2.csv', header=None)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTER ESTANDAR:\n",
    "splitter = langchain.text_splitter.RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20,\n",
    "    length_function = len)\n",
    "\n",
    "loader = CSVLoader(file_path='lista_test_2.csv')\n",
    "\n",
    "documentos = splitter.create_documents(csv_loaded,\n",
    "                          metadatas=[{'source': f'lista_test_2.csv pag{i}'} for i in list(range(len(csv_loaded)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# SPLITTER POR TOKENS: [NO FUNCIONA]\n",
    "import transformers\n",
    "tokenizador = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "gpt_splitter = langchain.text_splitter.CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizador, chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "documentos = gpt_splitter.create_documents(\n",
    "    csv_loaded,\n",
    "    metadatas=[{'source': f'lista_test_2.csv pag.{i}'}\n",
    "               for i in list(range(len(csv_loaded)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT4All CHAIN for QA:\n",
    "gpt4all_path = './data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin'\n",
    "llm = langchain.llms.gpt4all.GPT4All(model=gpt4all_path,\n",
    "                                     n_threads=12,\n",
    "                                     n_ctx=2000)\n",
    "opai_llm = langchain.llms.openai.OpenAI()\n",
    "embedding = langchain.embeddings.openai.OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-11 12:26:11,617] {posthog.py:15} INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "[2023-04-11 12:26:11,620] {__init__.py:79} INFO - Running Chroma using direct local API.\n",
      "[2023-04-11 12:26:11,643] {__init__.py:40} WARNING - Using embedded DuckDB with persistence: data will be stored in: ./data/vector_stores\n",
      "[2023-04-11 12:26:11,692] {ctypes.py:22} INFO - Successfully imported ClickHouse Connect C data optimizations\n",
      "[2023-04-11 12:26:11,701] {ctypes.py:31} INFO - Successfully import ClickHouse Connect C/Numpy optimizations\n",
      "[2023-04-11 12:26:11,715] {json_impl.py:45} INFO - Using python library for writing JSON byte strings\n",
      "[2023-04-11 12:26:12,023] {duckdb.py:434} INFO - loaded in 2675 embeddings\n",
      "[2023-04-11 12:26:12,025] {duckdb.py:444} INFO - loaded in 1 collections\n",
      "[2023-04-11 12:26:12,027] {duckdb.py:89} INFO - collection with name langchain already exists, returning existing collection\n"
     ]
    }
   ],
   "source": [
    "vector_store = langchain.vectorstores.Chroma.from_documents(documentos, embedding, persist_directory='./data/vector_stores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-10 16:28:02,582] {duckdb.py:392} INFO - Persisting DB to disk, putting it in the save folder: ./data/vector_stores\n"
     ]
    }
   ],
   "source": [
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperador = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI:\n",
    "cadena_OAI = langchain.chains.question_answering.load_qa_chain(llm=opai_llm)\n",
    "\n",
    "# GPT4ALL:\n",
    "cadena_GPT4all = langchain.chains.question_answering.load_qa_chain(llm=llm)\n",
    "\n",
    "# GPT4ALL Alternativa:\n",
    "esquema_pregunta = '''\n",
    "Find the answer to the following question:\n",
    "Question: {question}\n",
    "Using the following context:\n",
    "{context}\n",
    "Answer: '''\n",
    "prompt = langchain.PromptTemplate(\n",
    "    template = esquema_pregunta,\n",
    "    input_variables=['question', 'context'],\n",
    ")\n",
    "cadena_alt = langchain.LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm)\n",
    "\n",
    "# GPT4ALL Alternativa2:\n",
    "\n",
    "cadena_alt2 = langchain.chains.RetrievalQA.from_chain_type(llm=llm,\n",
    "                                                           chain_type='stuff',\n",
    "                                                           retriever=recuperador)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadena_alt2.run(pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='2,880 1,262 72% 7% -8% -34%;Tonnes of Scope ;2 CO2 emitted 0 0 0 102 1,101 2,245 2,565 179', metadata={'source': 'lista_test_2.csv pag90'}), Document(page_content='0 0 0 - - - -;Tonnes CO2/ / ;million units. 0.004 22.58 104.85 42.30 0.003 27.54 137.86', metadata={'source': 'lista_test_2.csv pag90'})]\n"
     ]
    }
   ],
   "source": [
    "pregunta = 'How much CO2 was emitted in total according to this document?'\n",
    "similares = vector_store.similarity_search(pregunta, include_metadata=True, top_k=5)\n",
    "print(similares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 498.73 tonnes of CO2 were emitted in total according to this document.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPENAI:\n",
    "cadena_OAI.run(\n",
    "    input_documents = similares,\n",
    "    question = pregunta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT4ALL:\n",
    "cadena_GPT4all.run(\n",
    "    input_documents = similares,\n",
    "    question = pregunta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nFind the answer to the following question:\\nQuestion: How much CO2 was emitted in total according to this document?\\nUsing the following context:\\n2,880 1,262 72% 7% -8% -34%;Tonnes of Scope ;2 CO2 emitted 0 0 0 102 1,101 2,245 2,565 179 0 0 0 - - - -;Tonnes CO2/ / ;million units. 0.004 22.58 104.85 42.30 0.003 27.54 137.86\\nAnswer: 3,976 tCO2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT4ALL con Cadena Alternativa:\n",
    "contexto_pregunta = f\"{' '.join(i.page_content for i in similares)}\"\n",
    "cadena_alt.run(\n",
    "    question = pregunta,\n",
    "    context = contexto_pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexto_pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='REPORT;20;20: 98www.rovi.es', metadata={'source': 'lista_test_2.csv', 'row': 96}),\n",
       " Document(page_content='REPORT;20;20: SHAREHOLDER COMPOSITION;63.11%;Norbel Inversores, S.L.;5.57%;Indumenta Pueri, S.L.;3.043%;T.Rowe Price International Funds, Inc;3.005%;Wellington Management Group, LLP;25.275%;Other;7', metadata={'source': 'lista_test_2.csv', 'row': 5}),\n",
       " Document(page_content='REPORT;20;20: –Profarma;Each year, in the Plan Profarma, the Ministry of Industry, Tourism and Trade and the Ministry ;of Health, Social Services and Equality classify the pharmaceutical Companies in accordance ;with their contribution to the Spanish industrial fabric, taking their investment in technology, ;new manufacturing plants, research efforts, etc. as a reference. In February 2020, the results ;of Plan Profarma 2019 were issued and ROVI obtained the classification of Excellent for the ;fourteenth consecutive year. ;KEY FIGURES;(million euros) 2020 2019 2018 2017;Total revenue 421.1 382.5  304.8 277.4;EBITDA 94.2 60.9 29.5 29.9;Net financial debt 19.8 15.9 -62.8 1.1;Employees 1.419 1.310 1.224 1.191102-7;14; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2020.0 + Total revenue = 421.1; KEY FIGURES + (million euros) + 2020.0 + EBITDA = 94.2; KEY FIGURES + (million euros) + 2020.0 + Net financial debt = 19.8; KEY FIGURES + (million euros) + 2020.0 + Employees = 1.419; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2019.0 + Total revenue = 382.5; KEY FIGURES + (million euros) + 2019.0 + EBITDA = 60.9; KEY FIGURES + (million euros) + 2019.0 + Net financial debt = 15.9; KEY FIGURES + (million euros) + 2019.0 + Employees = 1.31; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2018.0 + Total revenue = 304.8; KEY FIGURES + (million euros) + 2018.0 + EBITDA = 29.5; KEY FIGURES + (million euros) + 2018.0 + Net financial debt = -62.8; KEY FIGURES + (million euros) + 2018.0 + Employees = 1.224; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2017.0 + Total revenue = 277.4; KEY FIGURES + (million euros) + 2017.0 + EBITDA = 29.9; KEY FIGURES + (million euros) + 2017.0 + Net financial debt = 1.1; KEY FIGURES + (million euros) + 2017.0 + Employees = 1.191; ;', metadata={'source': 'lista_test_2.csv', 'row': 12}),\n",
       " Document(page_content='REPORT;20;20: Shareholders have the possibility of receiving ROVI’s financial information automatically ;through an e-mail alert system.  Furthermore, the group provides regular, prompt and ;relevant information on the company, such as presentations and legal documents on ;economic and financial aspects and corporate governance, which may be consulted in the ;Investors and Shareholders section of the corporate website www.rovi.es.;Coinciding with its General Shareholders’ Meeting, ROVI prepares an Integrated Report ;in which it summarises the strategic lines of its work and the activities carried out in ;the preceding year. This document forms part of the Informe Reporta, prepared by the ;consulting company Deva, which rates the reports published by the companies listed on the ;General Index of the Madrid Stock Exchange (IGBM) in accordance with the quality of the ;information they provide. In the 2020 edition of Informe Reporta, ROVI was in 22nd place of ;this ranking, which is formed by 120 companies, maintaining the same position as it held in ;2019.; –Customers;ROVI has a query channel for information requests from both international partners and ;direct customers, patients and professionals: www.bemimed.com.;In the event of a complaint, the company opens an enquiry immediately in order to identify ;the cause and prevent any repetition. Furthermore, there is a contact telephone number and ;the e-mail rovi@rovi.es where queries and complaints may be made.; –Society and environment;As a catalyst in its socioeconomic surroundings and aware of the impact of its activity on ;the environment, ROVI is committed, as an integral part of its day-to-day activity, to the ;protection of the environment, as well as to improving the situation of society in general and ;the different geographical areas  all over the world where it is present with its product or ;plants.;The company’s environmental policy is based on commitments to continuing improvement ;of products and processes, while, at the same time, complying with both legal requirements ;and additional voluntary requirements. In relation to environmental queries, ROVI has a ;corporate procedure through which it manages communications (queries, complaints, etc.) ;related to the environment and occupational health and safety. On the corporate website ;(www.rovi.es), the quality, environmental and occupational health and safety certifications ;held by group companies are available to the public. ;Over recent years, the company has carried out intensive activity to support research and ;promote prevention and knowledge of certain diseases. ROVI allocates part of its resources ;to driving medical and healthcare knowledge forward through contributions to different ;projects and co-operation with higher-education entities, with which it also works to help ;young professionals enter the workplace through scholarships and training. ;27', metadata={'source': 'lista_test_2.csv', 'row': 25})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pregunta = '¿De qué empresa es este informe?'\n",
    "similares = recuperador.get_relevant_documents(pregunta)\n",
    "cadena.run(input_documents = similares, question = pregunta)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdelt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
