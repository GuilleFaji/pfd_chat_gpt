{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GPT4ALL QA from docs:**\n",
    "**Para analizar grandes cantidades de datos el precio de OpenAI deja de ser trivial, por lo tanto se explora la posibilidad de usar modelos en local que realicen lo mismo pero con el nivel más parecido al SotA actual.\n",
    "Es por esto que se intenta usar [GPT4ALL](https://github.com/nomic-ai/gpt4all) y su implementación mediante librería [Langchain](https://python.langchain.com/en/latest/index.html#)**\n",
    "\n",
    "**Sin embargo, los embeddings de OPENAI siguen siendo baratos y efectivos, por lo que su uso sí tiene sentido**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "\n",
    "import pypdf\n",
    "import tabula\n",
    "\n",
    "import openai\n",
    "import pyllamacpp\n",
    "import tiktoken\n",
    "\n",
    "import langchain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.retrievers import SVMRetriever\n",
    "\n",
    "api_key = json.load(open('./data/creds/gpt_id.json'))['api_key']\n",
    "openai.api_key = api_key\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado Inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones esenciales de procesamiento:\n",
    "def limpieza_texto(texto: str) -> str:\n",
    "    '''\n",
    "    Función para limpiar texto de pdfs.\n",
    "    Cambia saltos de línea, espacios en blanco y caracteres especiales.\n",
    "    '''\n",
    "    # Eliminamos espacios en blanco\n",
    "    #texto = re.sub(' +', ' ', texto)\n",
    "    # Eliminamos caracteres especiales [REVISAR]\n",
    "    #texto = re.sub('[^A-Za-z0-9]+', ' ', texto)\n",
    "    # Eliminamos saltos múltiples de línea\n",
    "    texto = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", texto)\n",
    "    texto = re.sub(r\"\\n\", \";\", texto)\n",
    "    return texto\n",
    "\n",
    "def tabla_a_texto(tabla):\n",
    "    '''\n",
    "    Función para convertir una tabla de pandas en un texto.\n",
    "    La idea es identificar los nombres de columna e índices correctos y\n",
    "    a partir de ahí generar un texto que pueda ser procesado por el modelo.\n",
    "    '''\n",
    "    tabla = tabla.copy()\n",
    "    \n",
    "    # Tamaño mínimo de tabla para que sea válida = 2x2\n",
    "    if sum(tabla.shape) < 4:\n",
    "        return ''\n",
    "    \n",
    "    # Lista de valores que consideramos NaN:\n",
    "    nan_equivalents = [np.NaN, np.nan,\n",
    "                       'nan', 'NaN', 'Nan', 'NAN', 'na', 'NA',\n",
    "                       'Unnamed:0', 'Unnamed: 0'\n",
    "                       '', '-', ' ', '  ', '   ']\n",
    "    \n",
    "    # Asumimos que el primer elemento es el título salvo si es NaN:\n",
    "    titulo = tabla.columns[0] if tabla.columns[0] not in nan_equivalents else ''\n",
    "    \n",
    "    # Asumimos que la primera columna es el índice y la eliminamos:\n",
    "    tabla.index = tabla[tabla.columns[0]].values\n",
    "    tabla.drop(columns=tabla.columns[0], inplace=True)\n",
    "\n",
    "    # Si las columnas tienen muchos 'Unnamed' suele ser porque hay\n",
    "    # varias líneas de texto. En ese caso, las juntamos en una sola:\n",
    "    if sum(['Unnamed' in i for i in tabla.columns]) > 2:\n",
    "        nueva_columna = [f'{tabla.columns[i]} {tabla.iloc[0,i]}'\n",
    "                         for i in range(len(tabla.columns))]\n",
    "        nueva_columna = [i.replace('Unnamed: ','') for i in nueva_columna]\n",
    "        tabla.columns = nueva_columna\n",
    "\n",
    "    \n",
    "    # Eliminamos las filas y columnas que no tienen datos:\n",
    "    tabla.replace(nan_equivalents, np.nan, inplace=True)\n",
    "    tabla.dropna(axis=0, how='all', inplace=True)\n",
    "    tabla.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    # Check si las columnas son años:\n",
    "    col_años = False\n",
    "    years_txt=[str(i) for i in range(2015,2022)]\n",
    "    years_int=[i for i in range(2015,2022)]\n",
    "    years = set(years_txt+years_int)\n",
    "    cruce = set(tabla.columns).intersection(set(years))\n",
    "    if len(cruce) > 0: col_años=True\n",
    "    \n",
    "    # Si no son años las columnas, buscamos filas que sean años:\n",
    "    contexto = None\n",
    "    if not col_años:\n",
    "        for i in tabla.iterrows():\n",
    "            #print(i[1].values)\n",
    "            try:\n",
    "                cruce = set(i[1].values).intersection(set(years))\n",
    "            except:\n",
    "                cruce=[]\n",
    "            if len(cruce)>0: # Si encontramos una fila con años:\n",
    "                # Asignamos los años a las columnas:\n",
    "                tabla.columns = i[1].values\n",
    "                try: \n",
    "                    contexto = i[1].name\n",
    "                except:\n",
    "                    contexto = None\n",
    "                # Drop de la fila:\n",
    "                tabla.drop(i[0], inplace=True)\n",
    "                break\n",
    "    # Los procesos anteriores pueden haber dejado filas vacías, las eliminamos:\n",
    "    tabla.replace(nan_equivalents, np.nan, inplace=True)\n",
    "    tabla.dropna(axis=0, how='all', inplace=True)\n",
    "    tabla.dropna(axis=1, how='all', inplace=True)\n",
    "    # Pasamos a texto:\n",
    "    texto = ''\n",
    "    for i in tabla.items():\n",
    "        txt = [f' {titulo} + {i[0]} + {x[0]} = {x[1]}; '\n",
    "            for x in list(i[1].items())]\n",
    "        add= ''.join(txt)\n",
    "        if contexto:\n",
    "            txt = [f' {titulo} + {contexto} + {i[0]} + {x[0]} = {x[1]}; '\n",
    "                for x in list(i[1].items())]\n",
    "            add = ''.join(txt)\n",
    "        add = add.replace('  ',' ').replace('\\n','; ').replace('  ','')\n",
    "        texto += f';  Tabla={titulo}: {add}'\n",
    "    return texto\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> list:\n",
    "    '''\n",
    "    Función para extraer texto de un pdf y limpiarlo.\n",
    "    Devuelve una lista de str, cada una es una página del pdf.\n",
    "    '''\n",
    "    # Abrimos el pdf\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf = pypdf.PdfReader(f)\n",
    "        # Obtenemos el número de páginas\n",
    "        num_pags = len(pdf.pages)\n",
    "        count = 0\n",
    "        text = []\n",
    "        # Iteramos sobre las páginas\n",
    "        for pag in pdf.pages:\n",
    "            count +=1\n",
    "            texto_pagina = pag.extract_text()\n",
    "            tablas = tabula.read_pdf(pdf_path, pages=count)\n",
    "            for tabla in tablas:\n",
    "                texto_pagina += f'; {tabla_a_texto(tabla=tabla)}; '\n",
    "            texto_pagina = limpieza_texto(texto_pagina)\n",
    "            text.append(texto_pagina)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos el PDF:\n",
    "resultado = extract_text_from_pdf('./data/BME_Instituto_Broschure_mIA-X_A4_CMYK-U_v07.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_unido = ' '.join(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un csv con 1 fila por página\n",
    "with open('lista_test_2.csv', 'w', newline='') as file:\n",
    "    \n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows([[str(i)] for i in resultado])\n",
    "\n",
    "# Y entero como txt:\n",
    "with open('texto_test_2.txt', 'w', newline='') as file:\n",
    "    file.write(resultado_unido)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado de Langchain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el csv como una lista (para comprobar que se ha guardado bien):\n",
    "csv_loaded = list(pd.read_csv('lista_test_2.csv', header=None)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTER ESTANDAR:\n",
    "splitter = langchain.text_splitter.RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20,\n",
    "    length_function = len)\n",
    "\n",
    "loader = CSVLoader(file_path='lista_test_2.csv')\n",
    "\n",
    "documentos = splitter.create_documents(csv_loaded,\n",
    "                          metadatas=[{'source': f'lista_test_2.csv pag{i}'} for i in list(range(len(csv_loaded)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTER por Tokens - TikToken Tokenizer:\n",
    "def contador_tokens(texto, tokenizador= tiktoken.get_encoding('cl100k_base')):\n",
    "    return len(tokenizador.encode(texto, disallowed_special=()))\n",
    "\n",
    "tk_splitter = langchain.text_splitter.RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=35,\n",
    "    length_function = contador_tokens,\n",
    "    separators = ['\\n','\\r','\\t',' ','\\n\\n'])\n",
    "\n",
    "documentos = tk_splitter.create_documents(\n",
    "    resultado, \n",
    "    metadatas=[{'source': f'lista_test_2.csv pag.{i}'}\n",
    "               for i in list(range(len(csv_loaded)))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: ./data/vector_stores\n"
     ]
    }
   ],
   "source": [
    "embedding = langchain.embeddings.openai.OpenAIEmbeddings()\n",
    "vector_store = langchain.vectorstores.Chroma.from_documents(documentos, embedding, persist_directory='./data/vector_stores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1bd6471b-daf8-11ed-8cd3-6c6a77e568a6',\n",
       " '1bd6471c-daf8-11ed-994b-6c6a77e568a6',\n",
       " '1bd6471d-daf8-11ed-a658-6c6a77e568a6',\n",
       " '1bd6471e-daf8-11ed-a749-6c6a77e568a6',\n",
       " '1bd6471f-daf8-11ed-a208-6c6a77e568a6',\n",
       " '1bd64720-daf8-11ed-b111-6c6a77e568a6',\n",
       " '1bd64721-daf8-11ed-b617-6c6a77e568a6',\n",
       " '1bd64722-daf8-11ed-b74a-6c6a77e568a6',\n",
       " '1bd64723-daf8-11ed-aea7-6c6a77e568a6',\n",
       " '1bd64724-daf8-11ed-80fb-6c6a77e568a6',\n",
       " '1bd64725-daf8-11ed-b578-6c6a77e568a6',\n",
       " '1bd64726-daf8-11ed-97c4-6c6a77e568a6',\n",
       " '1bd64727-daf8-11ed-a0b0-6c6a77e568a6',\n",
       " '1bd64728-daf8-11ed-bf9b-6c6a77e568a6',\n",
       " '1bd64729-daf8-11ed-9de3-6c6a77e568a6',\n",
       " '1bd6472a-daf8-11ed-a45f-6c6a77e568a6',\n",
       " '1bd6472b-daf8-11ed-94e4-6c6a77e568a6',\n",
       " '1bd6472c-daf8-11ed-b4b7-6c6a77e568a6',\n",
       " '1bd6472d-daf8-11ed-8339-6c6a77e568a6',\n",
       " '1bd6472e-daf8-11ed-8566-6c6a77e568a6',\n",
       " '1bd6472f-daf8-11ed-a221-6c6a77e568a6',\n",
       " '1bd64730-daf8-11ed-b653-6c6a77e568a6',\n",
       " '1bd64731-daf8-11ed-9ef0-6c6a77e568a6',\n",
       " '1bd64732-daf8-11ed-a32d-6c6a77e568a6',\n",
       " '1bd64733-daf8-11ed-8aee-6c6a77e568a6',\n",
       " '1bd64734-daf8-11ed-aa52-6c6a77e568a6',\n",
       " '1bd64735-daf8-11ed-9ddf-6c6a77e568a6',\n",
       " '1bd64736-daf8-11ed-941b-6c6a77e568a6',\n",
       " '1bd64737-daf8-11ed-ac94-6c6a77e568a6',\n",
       " '1bd64738-daf8-11ed-88cc-6c6a77e568a6',\n",
       " '1bd64739-daf8-11ed-a8ff-6c6a77e568a6',\n",
       " '1bd6473a-daf8-11ed-9d01-6c6a77e568a6',\n",
       " '1bd6473b-daf8-11ed-a2ba-6c6a77e568a6',\n",
       " '1bd6473c-daf8-11ed-87c2-6c6a77e568a6',\n",
       " '1bd6473d-daf8-11ed-9d90-6c6a77e568a6',\n",
       " '1bd6473e-daf8-11ed-8a32-6c6a77e568a6',\n",
       " '1bd6473f-daf8-11ed-8bac-6c6a77e568a6',\n",
       " '1bd64740-daf8-11ed-9b94-6c6a77e568a6',\n",
       " '1bd64741-daf8-11ed-b920-6c6a77e568a6',\n",
       " '1bd64742-daf8-11ed-936b-6c6a77e568a6',\n",
       " '1bd64743-daf8-11ed-8d2b-6c6a77e568a6',\n",
       " '1bd64744-daf8-11ed-89d3-6c6a77e568a6',\n",
       " '1bd64745-daf8-11ed-9271-6c6a77e568a6',\n",
       " '1bd64746-daf8-11ed-a415-6c6a77e568a6',\n",
       " '1bd64747-daf8-11ed-b97c-6c6a77e568a6',\n",
       " '1bd64748-daf8-11ed-95e3-6c6a77e568a6',\n",
       " '1bd64749-daf8-11ed-8120-6c6a77e568a6',\n",
       " '1bd6474a-daf8-11ed-9669-6c6a77e568a6',\n",
       " '1bd6474b-daf8-11ed-b471-6c6a77e568a6',\n",
       " '1bd6474c-daf8-11ed-890c-6c6a77e568a6',\n",
       " '1bd6474d-daf8-11ed-9b1e-6c6a77e568a6',\n",
       " '1bd6474e-daf8-11ed-854b-6c6a77e568a6',\n",
       " '1bd6474f-daf8-11ed-bfdc-6c6a77e568a6',\n",
       " '1bd64750-daf8-11ed-89e8-6c6a77e568a6',\n",
       " '1bd64751-daf8-11ed-9238-6c6a77e568a6',\n",
       " '1bd64752-daf8-11ed-90cf-6c6a77e568a6',\n",
       " '1bd64753-daf8-11ed-9c06-6c6a77e568a6',\n",
       " '1bd64754-daf8-11ed-9cac-6c6a77e568a6',\n",
       " '1bd64755-daf8-11ed-b204-6c6a77e568a6',\n",
       " '1bd64756-daf8-11ed-bf7f-6c6a77e568a6',\n",
       " '1bd64757-daf8-11ed-b33d-6c6a77e568a6',\n",
       " '1bd64758-daf8-11ed-97b1-6c6a77e568a6',\n",
       " '1bd64759-daf8-11ed-9adf-6c6a77e568a6',\n",
       " '1bd6475a-daf8-11ed-b214-6c6a77e568a6',\n",
       " '1bd6475b-daf8-11ed-8aa3-6c6a77e568a6',\n",
       " '1bd6475c-daf8-11ed-8c81-6c6a77e568a6',\n",
       " '1bd6475d-daf8-11ed-b360-6c6a77e568a6',\n",
       " '1bd6475e-daf8-11ed-9e5d-6c6a77e568a6',\n",
       " '1bd6475f-daf8-11ed-8cf6-6c6a77e568a6',\n",
       " '1bd64760-daf8-11ed-80af-6c6a77e568a6',\n",
       " '1bd64761-daf8-11ed-9534-6c6a77e568a6',\n",
       " '1bd64762-daf8-11ed-9719-6c6a77e568a6',\n",
       " '1bd64763-daf8-11ed-8197-6c6a77e568a6',\n",
       " '1bd64764-daf8-11ed-91c4-6c6a77e568a6',\n",
       " '1bd64765-daf8-11ed-bd6a-6c6a77e568a6',\n",
       " '1bd64766-daf8-11ed-98d8-6c6a77e568a6',\n",
       " '1bd64767-daf8-11ed-9e28-6c6a77e568a6',\n",
       " '1bd64768-daf8-11ed-841e-6c6a77e568a6',\n",
       " '1bd64769-daf8-11ed-a6d1-6c6a77e568a6',\n",
       " '1bd6476a-daf8-11ed-82c6-6c6a77e568a6',\n",
       " '1bd6476b-daf8-11ed-8b55-6c6a77e568a6',\n",
       " '1bd6476c-daf8-11ed-b381-6c6a77e568a6',\n",
       " '1bd6476d-daf8-11ed-98b3-6c6a77e568a6',\n",
       " '1bd6476e-daf8-11ed-acae-6c6a77e568a6',\n",
       " '1bd6476f-daf8-11ed-adf1-6c6a77e568a6',\n",
       " '1bd64770-daf8-11ed-81c0-6c6a77e568a6',\n",
       " '1bd64771-daf8-11ed-a233-6c6a77e568a6',\n",
       " '1bd64772-daf8-11ed-881b-6c6a77e568a6',\n",
       " '1bd64773-daf8-11ed-930f-6c6a77e568a6',\n",
       " '1bd64774-daf8-11ed-912c-6c6a77e568a6',\n",
       " '1bd64775-daf8-11ed-a7c7-6c6a77e568a6',\n",
       " '1bd64776-daf8-11ed-83b9-6c6a77e568a6',\n",
       " '1bd64777-daf8-11ed-844b-6c6a77e568a6',\n",
       " '1bd64778-daf8-11ed-98c2-6c6a77e568a6',\n",
       " '1bd64779-daf8-11ed-aa6c-6c6a77e568a6',\n",
       " '1bd6477a-daf8-11ed-8be0-6c6a77e568a6',\n",
       " '1bd6477b-daf8-11ed-a504-6c6a77e568a6',\n",
       " '1bd66e3a-daf8-11ed-8c22-6c6a77e568a6',\n",
       " '1bd66e3b-daf8-11ed-a1c3-6c6a77e568a6',\n",
       " '1bd66e3c-daf8-11ed-83f2-6c6a77e568a6',\n",
       " '1bd66e3d-daf8-11ed-8fb1-6c6a77e568a6',\n",
       " '1bd66e3e-daf8-11ed-a234-6c6a77e568a6',\n",
       " '1bd66e3f-daf8-11ed-8836-6c6a77e568a6',\n",
       " '1bd66e40-daf8-11ed-bf36-6c6a77e568a6',\n",
       " '1bd66e41-daf8-11ed-a759-6c6a77e568a6',\n",
       " '1bd66e42-daf8-11ed-9fbd-6c6a77e568a6',\n",
       " '1bd66e43-daf8-11ed-bc46-6c6a77e568a6',\n",
       " '1bd66e44-daf8-11ed-827f-6c6a77e568a6',\n",
       " '1bd66e45-daf8-11ed-ba42-6c6a77e568a6',\n",
       " '1bd66e46-daf8-11ed-893c-6c6a77e568a6',\n",
       " '1bd66e47-daf8-11ed-a099-6c6a77e568a6',\n",
       " '1bd66e48-daf8-11ed-9cb6-6c6a77e568a6',\n",
       " '1bd66e49-daf8-11ed-bc23-6c6a77e568a6',\n",
       " '1bd66e4a-daf8-11ed-8f3f-6c6a77e568a6',\n",
       " '1bd66e4b-daf8-11ed-b455-6c6a77e568a6',\n",
       " '1bd66e4c-daf8-11ed-bc9a-6c6a77e568a6',\n",
       " '1bd66e4d-daf8-11ed-9c30-6c6a77e568a6',\n",
       " '1bd66e4e-daf8-11ed-b14d-6c6a77e568a6',\n",
       " '1bd66e4f-daf8-11ed-873b-6c6a77e568a6',\n",
       " '1bd66e50-daf8-11ed-9c83-6c6a77e568a6',\n",
       " '1bd66e51-daf8-11ed-bde2-6c6a77e568a6',\n",
       " '1bd66e52-daf8-11ed-8381-6c6a77e568a6',\n",
       " '1bd66e53-daf8-11ed-9c35-6c6a77e568a6',\n",
       " '1bd66e54-daf8-11ed-a8b0-6c6a77e568a6',\n",
       " '1bd66e55-daf8-11ed-97d1-6c6a77e568a6',\n",
       " '1bd66e56-daf8-11ed-810a-6c6a77e568a6',\n",
       " '1bd66e57-daf8-11ed-90ac-6c6a77e568a6',\n",
       " '1bd66e58-daf8-11ed-bbaf-6c6a77e568a6',\n",
       " '1bd66e59-daf8-11ed-a986-6c6a77e568a6',\n",
       " '1bd66e5a-daf8-11ed-a3ee-6c6a77e568a6',\n",
       " '1bd66e5b-daf8-11ed-adfe-6c6a77e568a6',\n",
       " '1bd66e5c-daf8-11ed-a415-6c6a77e568a6',\n",
       " '1bd66e5d-daf8-11ed-be64-6c6a77e568a6',\n",
       " '1bd66e5e-daf8-11ed-95b9-6c6a77e568a6',\n",
       " '1bd66e5f-daf8-11ed-be60-6c6a77e568a6',\n",
       " '1bd66e60-daf8-11ed-9b1f-6c6a77e568a6',\n",
       " '1bd66e61-daf8-11ed-9d30-6c6a77e568a6',\n",
       " '1bd66e62-daf8-11ed-9467-6c6a77e568a6',\n",
       " '1bd66e63-daf8-11ed-8cdb-6c6a77e568a6',\n",
       " '1bd66e64-daf8-11ed-b2f2-6c6a77e568a6',\n",
       " '1bd66e65-daf8-11ed-983d-6c6a77e568a6',\n",
       " '1bd66e66-daf8-11ed-bfae-6c6a77e568a6',\n",
       " '1bd66e67-daf8-11ed-8075-6c6a77e568a6',\n",
       " '1bd66e68-daf8-11ed-8a9b-6c6a77e568a6',\n",
       " '1bd66e69-daf8-11ed-93ac-6c6a77e568a6',\n",
       " '1bd66e6a-daf8-11ed-94bd-6c6a77e568a6',\n",
       " '1bd66e6b-daf8-11ed-936d-6c6a77e568a6',\n",
       " '1bd66e6c-daf8-11ed-80ed-6c6a77e568a6',\n",
       " '1bd66e6d-daf8-11ed-aefb-6c6a77e568a6',\n",
       " '1bd66e6e-daf8-11ed-ad4e-6c6a77e568a6',\n",
       " '1bd66e6f-daf8-11ed-8230-6c6a77e568a6',\n",
       " '1bd66e70-daf8-11ed-a370-6c6a77e568a6',\n",
       " '1bd66e71-daf8-11ed-b285-6c6a77e568a6',\n",
       " '1bd66e72-daf8-11ed-a735-6c6a77e568a6',\n",
       " '1bd66e73-daf8-11ed-87cd-6c6a77e568a6',\n",
       " '1bd66e74-daf8-11ed-87e6-6c6a77e568a6',\n",
       " '1bd66e75-daf8-11ed-9be6-6c6a77e568a6',\n",
       " '1bd66e76-daf8-11ed-9959-6c6a77e568a6',\n",
       " '1bd66e77-daf8-11ed-a332-6c6a77e568a6',\n",
       " '1bd66e78-daf8-11ed-a0d1-6c6a77e568a6',\n",
       " '1bd66e79-daf8-11ed-8ddd-6c6a77e568a6',\n",
       " '1bd66e7a-daf8-11ed-8aee-6c6a77e568a6',\n",
       " '1bd66e7b-daf8-11ed-af39-6c6a77e568a6',\n",
       " '1bd66e7c-daf8-11ed-b17f-6c6a77e568a6',\n",
       " '1bd66e7d-daf8-11ed-a890-6c6a77e568a6',\n",
       " '1bd66e7e-daf8-11ed-b70a-6c6a77e568a6',\n",
       " '1bd66e7f-daf8-11ed-9256-6c6a77e568a6',\n",
       " '1bd66e80-daf8-11ed-8f23-6c6a77e568a6',\n",
       " '1bd66e81-daf8-11ed-bd0b-6c6a77e568a6',\n",
       " '1bd66e82-daf8-11ed-a850-6c6a77e568a6',\n",
       " '1bd66e83-daf8-11ed-b9db-6c6a77e568a6',\n",
       " '1bd66e84-daf8-11ed-bca9-6c6a77e568a6',\n",
       " '1bd66e85-daf8-11ed-9485-6c6a77e568a6',\n",
       " '1bd66e86-daf8-11ed-a7d9-6c6a77e568a6',\n",
       " '1bd66e87-daf8-11ed-a0e0-6c6a77e568a6',\n",
       " '1bd66e88-daf8-11ed-af50-6c6a77e568a6',\n",
       " '1bd66e89-daf8-11ed-831f-6c6a77e568a6',\n",
       " '1bd66e8a-daf8-11ed-b84f-6c6a77e568a6',\n",
       " '1bd66e8b-daf8-11ed-977f-6c6a77e568a6',\n",
       " '1bd66e8c-daf8-11ed-b8d5-6c6a77e568a6',\n",
       " '1bd66e8d-daf8-11ed-87d2-6c6a77e568a6',\n",
       " '1bd66e8e-daf8-11ed-ac11-6c6a77e568a6',\n",
       " '1bd66e8f-daf8-11ed-b8eb-6c6a77e568a6',\n",
       " '1bd66e90-daf8-11ed-904e-6c6a77e568a6',\n",
       " '1bd66e91-daf8-11ed-ae71-6c6a77e568a6',\n",
       " '1bd66e92-daf8-11ed-b485-6c6a77e568a6',\n",
       " '1bd66e93-daf8-11ed-a959-6c6a77e568a6',\n",
       " '1bd66e94-daf8-11ed-9fc6-6c6a77e568a6',\n",
       " '1bd66e95-daf8-11ed-abec-6c6a77e568a6',\n",
       " '1bd66e96-daf8-11ed-970c-6c6a77e568a6',\n",
       " '1bd66e97-daf8-11ed-8101-6c6a77e568a6',\n",
       " '1bd66e98-daf8-11ed-89e2-6c6a77e568a6',\n",
       " '1bd66e99-daf8-11ed-991f-6c6a77e568a6',\n",
       " '1bd66e9a-daf8-11ed-ab23-6c6a77e568a6',\n",
       " '1bd66e9b-daf8-11ed-a99f-6c6a77e568a6',\n",
       " '1bd66e9c-daf8-11ed-ace7-6c6a77e568a6',\n",
       " '1bd66e9d-daf8-11ed-919a-6c6a77e568a6',\n",
       " '1bd66e9e-daf8-11ed-82f4-6c6a77e568a6',\n",
       " '1bd66e9f-daf8-11ed-a48d-6c6a77e568a6',\n",
       " '1bd66ea0-daf8-11ed-8652-6c6a77e568a6',\n",
       " '1bd66ea1-daf8-11ed-b920-6c6a77e568a6',\n",
       " '1bd66ea2-daf8-11ed-8b20-6c6a77e568a6',\n",
       " '1bd66ea3-daf8-11ed-9d74-6c6a77e568a6',\n",
       " '1bd66ea4-daf8-11ed-bdff-6c6a77e568a6',\n",
       " '1bd66ea5-daf8-11ed-b503-6c6a77e568a6',\n",
       " '1bd66ea6-daf8-11ed-bbe1-6c6a77e568a6',\n",
       " '1bd66ea7-daf8-11ed-804d-6c6a77e568a6',\n",
       " '1bd66ea8-daf8-11ed-b379-6c6a77e568a6',\n",
       " '1bd66ea9-daf8-11ed-a6d8-6c6a77e568a6',\n",
       " '1bd66eaa-daf8-11ed-8436-6c6a77e568a6',\n",
       " '1bd66eab-daf8-11ed-8b29-6c6a77e568a6',\n",
       " '1bd66eac-daf8-11ed-a7cb-6c6a77e568a6',\n",
       " '1bd66ead-daf8-11ed-aca5-6c6a77e568a6',\n",
       " '1bd66eae-daf8-11ed-881d-6c6a77e568a6',\n",
       " '1bd66eaf-daf8-11ed-b67d-6c6a77e568a6',\n",
       " '1bd66eb0-daf8-11ed-ba0e-6c6a77e568a6',\n",
       " '1bd66eb1-daf8-11ed-9c89-6c6a77e568a6',\n",
       " '1bd66eb2-daf8-11ed-ac53-6c6a77e568a6',\n",
       " '1bd66eb3-daf8-11ed-90c8-6c6a77e568a6',\n",
       " '1bd66eb4-daf8-11ed-83a8-6c6a77e568a6',\n",
       " '1bd66eb5-daf8-11ed-9c41-6c6a77e568a6',\n",
       " '1bd66eb6-daf8-11ed-a58e-6c6a77e568a6',\n",
       " '1bd66eb7-daf8-11ed-8e8d-6c6a77e568a6',\n",
       " '1bd66eb8-daf8-11ed-8029-6c6a77e568a6',\n",
       " '1bd66eb9-daf8-11ed-8833-6c6a77e568a6',\n",
       " '1bd66eba-daf8-11ed-bccd-6c6a77e568a6',\n",
       " '1bd66ebb-daf8-11ed-8e38-6c6a77e568a6',\n",
       " '1bd66ebc-daf8-11ed-8019-6c6a77e568a6',\n",
       " '1bd66ebd-daf8-11ed-a806-6c6a77e568a6',\n",
       " '1bd66ebe-daf8-11ed-9739-6c6a77e568a6',\n",
       " '1bd66ebf-daf8-11ed-8d51-6c6a77e568a6',\n",
       " '1bd66ec0-daf8-11ed-a147-6c6a77e568a6',\n",
       " '1bd66ec1-daf8-11ed-9c53-6c6a77e568a6',\n",
       " '1bd66ec2-daf8-11ed-ac15-6c6a77e568a6',\n",
       " '1bd66ec3-daf8-11ed-8e26-6c6a77e568a6',\n",
       " '1bd66ec4-daf8-11ed-95bf-6c6a77e568a6',\n",
       " '1bd66ec5-daf8-11ed-b03d-6c6a77e568a6',\n",
       " '1bd66ec6-daf8-11ed-ae6f-6c6a77e568a6',\n",
       " '1bd66ec7-daf8-11ed-8106-6c6a77e568a6',\n",
       " '1bd66ec8-daf8-11ed-afc8-6c6a77e568a6',\n",
       " '1bd66ec9-daf8-11ed-8086-6c6a77e568a6',\n",
       " '1bd66eca-daf8-11ed-a52e-6c6a77e568a6',\n",
       " '1bd66ecb-daf8-11ed-832f-6c6a77e568a6',\n",
       " '1bd66ecc-daf8-11ed-af41-6c6a77e568a6',\n",
       " '1bd66ecd-daf8-11ed-991d-6c6a77e568a6',\n",
       " '1bd66ece-daf8-11ed-8f5c-6c6a77e568a6',\n",
       " '1bd66ecf-daf8-11ed-a754-6c6a77e568a6',\n",
       " '1bd66ed0-daf8-11ed-8795-6c6a77e568a6',\n",
       " '1bd66ed1-daf8-11ed-bb36-6c6a77e568a6',\n",
       " '1bd66ed2-daf8-11ed-96b6-6c6a77e568a6',\n",
       " '1bd66ed3-daf8-11ed-a741-6c6a77e568a6',\n",
       " '1bd66ed4-daf8-11ed-afd0-6c6a77e568a6',\n",
       " '1bd66ed5-daf8-11ed-9421-6c6a77e568a6',\n",
       " '1bd66ed6-daf8-11ed-a7a6-6c6a77e568a6',\n",
       " '1bd66ed7-daf8-11ed-a116-6c6a77e568a6',\n",
       " '1bd66ed8-daf8-11ed-900f-6c6a77e568a6',\n",
       " '1bd66ed9-daf8-11ed-acc1-6c6a77e568a6',\n",
       " '1bd66eda-daf8-11ed-8376-6c6a77e568a6',\n",
       " '1bd66edb-daf8-11ed-84a1-6c6a77e568a6',\n",
       " '1bd66edc-daf8-11ed-928b-6c6a77e568a6',\n",
       " '1bd66edd-daf8-11ed-b221-6c6a77e568a6',\n",
       " '1bd66ede-daf8-11ed-a490-6c6a77e568a6',\n",
       " '1bd66edf-daf8-11ed-8005-6c6a77e568a6',\n",
       " '1bd66ee0-daf8-11ed-89e4-6c6a77e568a6',\n",
       " '1bd66ee1-daf8-11ed-8cff-6c6a77e568a6',\n",
       " '1bd66ee2-daf8-11ed-bc84-6c6a77e568a6',\n",
       " '1bd66ee3-daf8-11ed-9d9c-6c6a77e568a6',\n",
       " '1bd66ee4-daf8-11ed-929c-6c6a77e568a6',\n",
       " '1bd66ee5-daf8-11ed-929c-6c6a77e568a6',\n",
       " '1bd66ee6-daf8-11ed-b116-6c6a77e568a6',\n",
       " '1bd66ee7-daf8-11ed-b8cb-6c6a77e568a6',\n",
       " '1bd66ee8-daf8-11ed-be6f-6c6a77e568a6',\n",
       " '1bd66ee9-daf8-11ed-bbcd-6c6a77e568a6',\n",
       " '1bd66eea-daf8-11ed-b3e4-6c6a77e568a6',\n",
       " '1bd66eeb-daf8-11ed-805a-6c6a77e568a6',\n",
       " '1bd66eec-daf8-11ed-8193-6c6a77e568a6',\n",
       " '1bd66eed-daf8-11ed-b400-6c6a77e568a6',\n",
       " '1bd66eee-daf8-11ed-8389-6c6a77e568a6',\n",
       " '1bd66eef-daf8-11ed-a177-6c6a77e568a6',\n",
       " '1bd66ef0-daf8-11ed-bf87-6c6a77e568a6',\n",
       " '1bd66ef1-daf8-11ed-a19d-6c6a77e568a6',\n",
       " '1bd66ef2-daf8-11ed-a79e-6c6a77e568a6',\n",
       " '1bd66ef3-daf8-11ed-b440-6c6a77e568a6',\n",
       " '1bd66ef4-daf8-11ed-b369-6c6a77e568a6',\n",
       " '1bd66ef5-daf8-11ed-81ab-6c6a77e568a6',\n",
       " '1bd66ef6-daf8-11ed-960a-6c6a77e568a6',\n",
       " '1bd66ef7-daf8-11ed-a755-6c6a77e568a6',\n",
       " '1bd66ef8-daf8-11ed-887c-6c6a77e568a6',\n",
       " '1bd66ef9-daf8-11ed-8316-6c6a77e568a6',\n",
       " '1bd66efa-daf8-11ed-b461-6c6a77e568a6',\n",
       " '1bd66efb-daf8-11ed-a7fa-6c6a77e568a6',\n",
       " '1bd66efc-daf8-11ed-8cb2-6c6a77e568a6',\n",
       " '1bd66efd-daf8-11ed-97c4-6c6a77e568a6',\n",
       " '1bd66efe-daf8-11ed-bcee-6c6a77e568a6',\n",
       " '1bd66eff-daf8-11ed-af07-6c6a77e568a6',\n",
       " '1bd66f00-daf8-11ed-83c4-6c6a77e568a6',\n",
       " '1bd66f01-daf8-11ed-a733-6c6a77e568a6',\n",
       " '1bd66f02-daf8-11ed-b080-6c6a77e568a6',\n",
       " '1bd66f03-daf8-11ed-930a-6c6a77e568a6',\n",
       " '1bd66f04-daf8-11ed-b15e-6c6a77e568a6',\n",
       " '1bd66f05-daf8-11ed-ac06-6c6a77e568a6',\n",
       " '1bd66f06-daf8-11ed-8a89-6c6a77e568a6',\n",
       " '1bd66f07-daf8-11ed-843f-6c6a77e568a6',\n",
       " '1bd66f08-daf8-11ed-a093-6c6a77e568a6',\n",
       " '1bd66f09-daf8-11ed-be93-6c6a77e568a6',\n",
       " '1bd66f0a-daf8-11ed-a25f-6c6a77e568a6',\n",
       " '1bd66f0b-daf8-11ed-b97d-6c6a77e568a6',\n",
       " '1bd66f0c-daf8-11ed-8616-6c6a77e568a6',\n",
       " '1bd66f0d-daf8-11ed-9e2a-6c6a77e568a6',\n",
       " '1bd66f0e-daf8-11ed-a9e4-6c6a77e568a6',\n",
       " '1bd66f0f-daf8-11ed-85a1-6c6a77e568a6',\n",
       " '1bd66f10-daf8-11ed-a125-6c6a77e568a6',\n",
       " '1bd66f11-daf8-11ed-9e98-6c6a77e568a6',\n",
       " '1bd66f12-daf8-11ed-9bf5-6c6a77e568a6',\n",
       " '1bd66f13-daf8-11ed-bfd8-6c6a77e568a6',\n",
       " '1bd66f14-daf8-11ed-a023-6c6a77e568a6',\n",
       " '1bd66f15-daf8-11ed-ac37-6c6a77e568a6',\n",
       " '1bd66f16-daf8-11ed-b676-6c6a77e568a6',\n",
       " '1bd66f17-daf8-11ed-8e89-6c6a77e568a6',\n",
       " '1bd66f18-daf8-11ed-b838-6c6a77e568a6',\n",
       " '1bd66f19-daf8-11ed-a055-6c6a77e568a6',\n",
       " '1bd66f1a-daf8-11ed-a58a-6c6a77e568a6',\n",
       " '1bd66f1b-daf8-11ed-98c5-6c6a77e568a6',\n",
       " '1bd6954a-daf8-11ed-98a8-6c6a77e568a6',\n",
       " '1bd6954b-daf8-11ed-a74e-6c6a77e568a6',\n",
       " '1bd6954c-daf8-11ed-8961-6c6a77e568a6',\n",
       " '1bd6954d-daf8-11ed-ae49-6c6a77e568a6',\n",
       " '1bd6954e-daf8-11ed-97e0-6c6a77e568a6',\n",
       " '1bd6954f-daf8-11ed-a071-6c6a77e568a6',\n",
       " '1bd69550-daf8-11ed-81bf-6c6a77e568a6',\n",
       " '1bd69551-daf8-11ed-a601-6c6a77e568a6',\n",
       " '1bd69552-daf8-11ed-b9bf-6c6a77e568a6',\n",
       " '1bd69553-daf8-11ed-9da7-6c6a77e568a6',\n",
       " '1bd69554-daf8-11ed-9c88-6c6a77e568a6',\n",
       " '1bd69555-daf8-11ed-aeca-6c6a77e568a6',\n",
       " '1bd69556-daf8-11ed-9d99-6c6a77e568a6',\n",
       " '1bd69557-daf8-11ed-b88a-6c6a77e568a6',\n",
       " '1bd69558-daf8-11ed-bf58-6c6a77e568a6',\n",
       " '1bd69559-daf8-11ed-a4b8-6c6a77e568a6',\n",
       " '1bd6955a-daf8-11ed-8891-6c6a77e568a6',\n",
       " '1bd6955b-daf8-11ed-bf50-6c6a77e568a6',\n",
       " '1bd6955c-daf8-11ed-a421-6c6a77e568a6',\n",
       " '1bd6955d-daf8-11ed-88f8-6c6a77e568a6',\n",
       " '1bd6955e-daf8-11ed-ada0-6c6a77e568a6',\n",
       " '1bd6955f-daf8-11ed-b2ed-6c6a77e568a6',\n",
       " '1bd69560-daf8-11ed-9cd8-6c6a77e568a6',\n",
       " '1bd69561-daf8-11ed-aac9-6c6a77e568a6',\n",
       " '1bd69562-daf8-11ed-bf74-6c6a77e568a6',\n",
       " '1bd69563-daf8-11ed-b0f5-6c6a77e568a6',\n",
       " '1bd69564-daf8-11ed-99c6-6c6a77e568a6',\n",
       " '1bd69565-daf8-11ed-b132-6c6a77e568a6',\n",
       " '1bd69566-daf8-11ed-8efb-6c6a77e568a6',\n",
       " '1bd69567-daf8-11ed-84fb-6c6a77e568a6',\n",
       " '1bd69568-daf8-11ed-a6dd-6c6a77e568a6',\n",
       " '1bd69569-daf8-11ed-9245-6c6a77e568a6',\n",
       " '1bd6956a-daf8-11ed-98d6-6c6a77e568a6',\n",
       " '1bd6956b-daf8-11ed-99be-6c6a77e568a6',\n",
       " '1bd6956c-daf8-11ed-8855-6c6a77e568a6',\n",
       " '1bd6956d-daf8-11ed-8f43-6c6a77e568a6',\n",
       " '1bd6956e-daf8-11ed-a96a-6c6a77e568a6',\n",
       " '1bd6956f-daf8-11ed-a5d0-6c6a77e568a6',\n",
       " '1bd69570-daf8-11ed-951a-6c6a77e568a6',\n",
       " '1bd69571-daf8-11ed-97a3-6c6a77e568a6',\n",
       " '1bd69572-daf8-11ed-8ea1-6c6a77e568a6',\n",
       " '1bd69573-daf8-11ed-9e40-6c6a77e568a6',\n",
       " '1bd69574-daf8-11ed-a281-6c6a77e568a6',\n",
       " '1bd69575-daf8-11ed-8305-6c6a77e568a6',\n",
       " '1bd69576-daf8-11ed-bdc6-6c6a77e568a6',\n",
       " '1bd69577-daf8-11ed-9c94-6c6a77e568a6',\n",
       " '1bd69578-daf8-11ed-94a5-6c6a77e568a6',\n",
       " '1bd69579-daf8-11ed-a9db-6c6a77e568a6',\n",
       " '1bd6957a-daf8-11ed-a081-6c6a77e568a6',\n",
       " '1bd6957b-daf8-11ed-b3f1-6c6a77e568a6',\n",
       " '1bd6957c-daf8-11ed-a7db-6c6a77e568a6',\n",
       " '1bd6957d-daf8-11ed-92aa-6c6a77e568a6',\n",
       " '1bd6957e-daf8-11ed-ab5f-6c6a77e568a6',\n",
       " '1bd6957f-daf8-11ed-a301-6c6a77e568a6',\n",
       " '1bd69580-daf8-11ed-bb9f-6c6a77e568a6',\n",
       " '1bd69581-daf8-11ed-a40a-6c6a77e568a6',\n",
       " '1bd69582-daf8-11ed-aa63-6c6a77e568a6',\n",
       " '1bd69583-daf8-11ed-853e-6c6a77e568a6',\n",
       " '1bd69584-daf8-11ed-bcd5-6c6a77e568a6',\n",
       " '1bd69585-daf8-11ed-bd7d-6c6a77e568a6',\n",
       " '1bd69586-daf8-11ed-a5cf-6c6a77e568a6',\n",
       " '1bd69587-daf8-11ed-a5b2-6c6a77e568a6',\n",
       " '1bd69588-daf8-11ed-9cff-6c6a77e568a6',\n",
       " '1bd69589-daf8-11ed-8e5d-6c6a77e568a6',\n",
       " '1bd6958a-daf8-11ed-a406-6c6a77e568a6',\n",
       " '1bd6958b-daf8-11ed-89c3-6c6a77e568a6',\n",
       " '1bd6958c-daf8-11ed-ac3a-6c6a77e568a6',\n",
       " '1bd6958d-daf8-11ed-94b5-6c6a77e568a6',\n",
       " '1bd6958e-daf8-11ed-bb0d-6c6a77e568a6',\n",
       " '1bd6958f-daf8-11ed-8ea2-6c6a77e568a6',\n",
       " '1bd69590-daf8-11ed-8c80-6c6a77e568a6']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.persist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=';de conocimiento, te llevas compañeros del mismo gremio con los que te ;ayudarás siempre. Por todo ello, mi experiencia fue más que positiva. Este ;máster te proporciona ese rasgo diferenciador que tan demandado es ac -;tualmente por las empresas del sector. Sin duda, lo recomiendo.CELSO OTERO GARCÍA (6ª EDICIÓN);Responsable Departamento Inteligencia Artificial Renta 4 Banco;Llevo en torno a 20 años en el mundo financiero desempeñando dis tintas tar -;eas, análisis, gestión de fondos, desarrollo de productos, etc. En este período, ;la fo rma de desempeñar el trabajo ha sufrido una evolución constante. ;La capacidad de', metadata={'source': 'lista_test_2.csv pag.8'}), Document(page_content='de resaltar que este es un máster de intensidad ;elevada. En media, el 30% de los alumnos no consiguen ;terminarlo. Para adquirir los conocimientos en Progra -;mación, Bolsa, Big Data, Inteligencia Artificial, Blockchain ;y Computación Cuántica hay que estudiar a diario. A con -;tinuación, desglosamos la intensidad del programa.;– Horas lectivas de clase 750 horas;– TFM (trabajo de fin de máster) De 600 a 800 horas;–  Resolución de prácticas (10 prácticas x 3 semanas cada ;una x 3 horas de dedicación al día) 630 horas;Estamos hablando de un máster de más de 2.000 horas ;de dedicación, equivalentes a 80', metadata={'source': 'lista_test_2.csv pag.3'}), Document(page_content='muy completo. ;La realidad, superó las expectativas. Vimos, no solo el contenido más pun -;tero, si no su explicación desde la base, lo que proporciona una importante ;visión para poder generar nuevas ideas. El máster exige una elevada dedi -;cación, el temario es extremadamente extenso, pero muy bien explicado ;por un gran equipo docente, el cual no sólo da una visión teórica, sino que ;está acompañado de un enfoque tremendamente aplicable. ;Todo lo aprendido de Machine Learning, aprendizaje por refuerzo, proc -;esamiento del lenguaje natural, uso de la nube y demás temario, ya se han ;traducido en distintos proyectos', metadata={'source': 'lista_test_2.csv pag.8'}), Document(page_content=';big data, inteligencia artificial, blockchain y computación;cuántica serán adquiridos por el alumno a lo largo del ;máster.;;METODOLOGÍA;Todas las sesiones estarán enfocadas con un gran con -;tenido práctico. ;Los alumnos del máster obtendrán competencias reales ;de programación en R y Python mediante diferentes ;plataformas como Google TensorFlow o Keras, así como ;avanzados conocimientos, demostrables, en la aplicación ;de algoritmos de Machine Learning, Deep Learning , ;Blockchain y Computación Cuántica.;La evaluación de los conocimientos adquiridos se re -;alizará mediante la entrega de diversas prácticas, en ;donde los alumnos dispondrán de un mínimo de 3 se', metadata={'source': 'lista_test_2.csv pag.2'})]\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTA\n",
    "pregunta = 'What can you learn in this Master?'\n",
    "similares = vector_store.similarity_search(pregunta, include_metadata=True, top_k=5)\n",
    "print(similares)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Cadena de OpenAI funcional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Chroma' object has no attribute 'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_store\u001b[39m.\u001b[39;49membeddings\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Chroma' object has no attribute 'embeddings'"
     ]
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperador = SVMRetriever.from_texts([i.page_content for i in documentos], embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=';de conocimiento, te llevas compañeros del mismo gremio con los que te ;ayudarás siempre. Por todo ello, mi experiencia fue más que positiva. Este ;máster te proporciona ese rasgo diferenciador que tan demandado es ac -;tualmente por las empresas del sector. Sin duda, lo recomiendo.CELSO OTERO GARCÍA (6ª EDICIÓN);Responsable Departamento Inteligencia Artificial Renta 4 Banco;Llevo en torno a 20 años en el mundo financiero desempeñando dis tintas tar -;eas, análisis, gestión de fondos, desarrollo de productos, etc. En este período, ;la fo rma de desempeñar el trabajo ha sufrido una evolución constante. ;La capacidad de', metadata={}),\n",
       " Document(page_content='de resaltar que este es un máster de intensidad ;elevada. En media, el 30% de los alumnos no consiguen ;terminarlo. Para adquirir los conocimientos en Progra -;mación, Bolsa, Big Data, Inteligencia Artificial, Blockchain ;y Computación Cuántica hay que estudiar a diario. A con -;tinuación, desglosamos la intensidad del programa.;– Horas lectivas de clase 750 horas;– TFM (trabajo de fin de máster) De 600 a 800 horas;–  Resolución de prácticas (10 prácticas x 3 semanas cada ;una x 3 horas de dedicación al día) 630 horas;Estamos hablando de un máster de más de 2.000 horas ;de dedicación, equivalentes a 80', metadata={}),\n",
       " Document(page_content='muy completo. ;La realidad, superó las expectativas. Vimos, no solo el contenido más pun -;tero, si no su explicación desde la base, lo que proporciona una importante ;visión para poder generar nuevas ideas. El máster exige una elevada dedi -;cación, el temario es extremadamente extenso, pero muy bien explicado ;por un gran equipo docente, el cual no sólo da una visión teórica, sino que ;está acompañado de un enfoque tremendamente aplicable. ;Todo lo aprendido de Machine Learning, aprendizaje por refuerzo, proc -;esamiento del lenguaje natural, uso de la nube y demás temario, ya se han ;traducido en distintos proyectos', metadata={}),\n",
       " Document(page_content='de Ma -;chine o Deep Learning que hace un año eran conceptos inconexos para mí.;Exigencia y Rigurosidad;Es un máster exigente en el estudio y trabajo requerido por la cantidad de ;materia y por la rigurosidad del trabajo científico. No solo les importa el ;“para qué sirve esto”, sino el por qué funciona o no funciona. La metodolo -;gía seguida es robusta desde un punto de vista científico.; Profesorado  ;El equipo docente es de alta calidad. En lugar de piezas sueltas, destacaría ;su funcionamiento como eslabones de una cadena bien engrasada.;Contenido;Por último, el propio contenido del máster es tremendamente atractivo, no ;solo por', metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuperador.get_relevant_documents(pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un modelo recuperador (busca en embeddings)\n",
    "# recuperador = vector_store.as_retriever(\n",
    "#     search_kwargs={'top_k': 5, 'include_metadata': True}\n",
    "# )\n",
    "\n",
    "# Definimos el modelo de OpenAI:\n",
    "openaillm = langchain.llms.openai.OpenAI(\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "\n",
    "# Cadena (orquestador de la respuesta)\n",
    "cadena_openai = langchain.chains.RetrievalQA.from_chain_type(\n",
    "    chain_type='stuff',\n",
    "    retriever=recuperador,\n",
    "    llm=openaillm,\n",
    "    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What can you learn in this Master?',\n",
       " 'result': ' In this Master, you can learn Machine Learning, reinforcement learning, natural language processing, cloud computing, and more.',\n",
       " 'source_documents': [Document(page_content=';de conocimiento, te llevas compañeros del mismo gremio con los que te ;ayudarás siempre. Por todo ello, mi experiencia fue más que positiva. Este ;máster te proporciona ese rasgo diferenciador que tan demandado es ac -;tualmente por las empresas del sector. Sin duda, lo recomiendo.CELSO OTERO GARCÍA (6ª EDICIÓN);Responsable Departamento Inteligencia Artificial Renta 4 Banco;Llevo en torno a 20 años en el mundo financiero desempeñando dis tintas tar -;eas, análisis, gestión de fondos, desarrollo de productos, etc. En este período, ;la fo rma de desempeñar el trabajo ha sufrido una evolución constante. ;La capacidad de', metadata={}),\n",
       "  Document(page_content='de resaltar que este es un máster de intensidad ;elevada. En media, el 30% de los alumnos no consiguen ;terminarlo. Para adquirir los conocimientos en Progra -;mación, Bolsa, Big Data, Inteligencia Artificial, Blockchain ;y Computación Cuántica hay que estudiar a diario. A con -;tinuación, desglosamos la intensidad del programa.;– Horas lectivas de clase 750 horas;– TFM (trabajo de fin de máster) De 600 a 800 horas;–  Resolución de prácticas (10 prácticas x 3 semanas cada ;una x 3 horas de dedicación al día) 630 horas;Estamos hablando de un máster de más de 2.000 horas ;de dedicación, equivalentes a 80', metadata={}),\n",
       "  Document(page_content='muy completo. ;La realidad, superó las expectativas. Vimos, no solo el contenido más pun -;tero, si no su explicación desde la base, lo que proporciona una importante ;visión para poder generar nuevas ideas. El máster exige una elevada dedi -;cación, el temario es extremadamente extenso, pero muy bien explicado ;por un gran equipo docente, el cual no sólo da una visión teórica, sino que ;está acompañado de un enfoque tremendamente aplicable. ;Todo lo aprendido de Machine Learning, aprendizaje por refuerzo, proc -;esamiento del lenguaje natural, uso de la nube y demás temario, ya se han ;traducido en distintos proyectos', metadata={}),\n",
       "  Document(page_content='de Ma -;chine o Deep Learning que hace un año eran conceptos inconexos para mí.;Exigencia y Rigurosidad;Es un máster exigente en el estudio y trabajo requerido por la cantidad de ;materia y por la rigurosidad del trabajo científico. No solo les importa el ;“para qué sirve esto”, sino el por qué funciona o no funciona. La metodolo -;gía seguida es robusta desde un punto de vista científico.; Profesorado  ;El equipo docente es de alta calidad. En lugar de piezas sueltas, destacaría ;su funcionamiento como eslabones de una cadena bien engrasada.;Contenido;Por último, el propio contenido del máster es tremendamente atractivo, no ;solo por', metadata={})]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado con sources:\n",
    "cadena_openai({'query': pregunta})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test con GPT4ALL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4all_path = './data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin'\n",
    "callback = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "gpt4allm = langchain.llms.gpt4all.GPT4All(model=gpt4all_path,\n",
    "                                          n_threads=12,\n",
    "                                          callback_manager=callback,\n",
    "                                          n_ctx=2000)\n",
    "\n",
    "cadena_gpt4all = langchain.chains.RetrievalQA.from_chain_type(\n",
    "    chain_type='stuff',\n",
    "    retriever=recuperador,\n",
    "    llm=gpt4allm,\n",
    "    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How much CO2 was emitted in total according to this document? The ammount usually is in Tonnes of CO2.',\n",
       " 'result': ' According to the document, the total CO2 emitted was 8,871 tonnes.',\n",
       " 'source_documents': [Document(page_content='Distr.  Gr Mad  ;y SSRR AH Distr. ;Tonnes of Scope 1 ;CO2 emitted 805 1,494 2,663 836 468 1,399 2,880 1,262 72% 7% -8% -34%;Tonnes of Scope ;2 CO2 emitted 0 0 0 102 1,101 2,245 2,565 179 -100% -100% -100% -43%;Tonnes of Scope ;2 CO2 avoided (*) 1,193 2,198 2,999 96 0 0 0 0 - - - -;Tonnes CO2/ / ;million units. 0.004 22.58 104.85 42.30 0.003 27.54 137.86 71.42 38% -18% -24% -41%305-1;91; ;  Tabla=:  + 1 Granada + nan = Granada;+ 1 Granada + CO2 emitted = 805;+ 1 Granada + 2 CO2 emitted = 0;+ 1', metadata={'source': 'lista_test_2.csv pag90'}),\n",
       "  Document(page_content='7% -8% -34%;Tonnes of Scope ;2 CO2 emitted 0 0 0 102 1,101 2,245 2,565 179 -100% -100% -100% -43%;Tonnes of Scope ;2 CO2 avoided (*) 1,193 2,198 2,999 96 0 0 0 0 - - - -;Tonnes CO2/ / ;million units. 0.004 22.58 104.85 42.30 0.003 27.54 137.86 71.42 38% -18% -24% -41%305-1;91; ;  Tabla=:  + 1 Granada + nan = Granada;+ 1 Granada + CO2 emitted = 805;+ 1 Granada + 2 CO2 emitted = 0;+ 1 Granada + 2 CO2 avoided (*) = 1,193;+ 1 Granada + million units. = 0.004; ;  Tabla=:  + Madrid', metadata={'source': 'lista_test_2.csv pag.90'})]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado con sources:\n",
    "cadena_openai({'query': pregunta})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4All-J:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4all_j_path = './data/models/gpt4all-7B/ggml-gpt4all-j.bin'\n",
    "\n",
    "gpt4alljm = langchain.llms.gpt4all.GPT4All(model=gpt4all_j_path,\n",
    "                                          n_threads=12,\n",
    "                                          callback_manager=callback,\n",
    "                                          n_ctx=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos:\n",
    "gpt4all_path = './data/models/gpt4all-7B/gpt4all-lora-quantized_new.bin'\n",
    "gpt4all_j_path = './data/models/gpt4all-7B/ggml-gpt4all-j.bin'\n",
    "\n",
    "gpt4a = langchain.llms.gpt4all.GPT4All(model=gpt4all_path,\n",
    "                                     n_threads=12,\n",
    "                                     n_ctx=2000)\n",
    "\n",
    "# gpt4aj = langchain.llms.gpt4all.GPT4All(model=gpt4all_j_path,\n",
    "#                                      n_threads=12)\n",
    "\n",
    "opai_llm = langchain.llms.openai.OpenAI(callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperador = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI:\n",
    "cadena_OAI = langchain.chains.question_answering.load_qa_chain(llm=opai_llm)\n",
    "\n",
    "# GPT4ALL:\n",
    "cadena_GPT4all = langchain.chains.question_answering.load_qa_chain(llm=gpt4a)\n",
    "\n",
    "# GPT4ALL Alternativa:\n",
    "esquema_pregunta = '''\n",
    "Find the answer to the following question:\n",
    "Question: {question}\n",
    "Using the following context:\n",
    "{context}\n",
    "Answer: '''\n",
    "prompt = langchain.PromptTemplate(\n",
    "    template = esquema_pregunta,\n",
    "    input_variables=['question', 'context'],\n",
    ")\n",
    "cadena_alt = langchain.LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=gpt4a)\n",
    "\n",
    "# GPT4ALL Alternativa2:\n",
    "\n",
    "cadena_alt2 = langchain.chains.RetrievalQA.from_chain_type(llm=gpt4a,\n",
    "                                                           chain_type='stuff',\n",
    "                                                           retriever=recuperador)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cadena_alt2\u001b[39m.\u001b[39;49mrun(pregunta)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:213\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:110\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m question \u001b[39m=\u001b[39m inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key]\n\u001b[0;32m    109\u001b[0m docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)\n\u001b[1;32m--> 110\u001b[0m answer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mcombine_docs(docs, question\u001b[39m=\u001b[39;49mquestion)\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n\u001b[0;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer, \u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m: docs}\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:89\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs), {}\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:151\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    138\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:57\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:118\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[0;32m    117\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:62\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list)\n\u001b[1;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(prompts, stop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:107\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m, prompts: List[PromptValue], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    106\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:140\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:137\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:324\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    322\u001b[0m generations \u001b[39m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m--> 324\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    325\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[0;32m    326\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\gpt4all.py:177\u001b[0m, in \u001b[0;36mGPT4All._call\u001b[1;34m(self, prompt, stop)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Call out to GPT4All's generate method.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39m            response = model(prompt, n_predict=55)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    178\u001b[0m         prompt,\n\u001b[0;32m    179\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_params,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m stop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         text \u001b[39m=\u001b[39m enforce_stop_tokens(text, stop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pyllamacpp\\model.py:112\u001b[0m, in \u001b[0;36mModel.generate\u001b[1;34m(self, prompt, n_predict, new_text_callback, verbose, **gpt_params)\u001b[0m\n\u001b[0;32m    109\u001b[0m Model\u001b[39m.\u001b[39m_new_text_callback \u001b[39m=\u001b[39m new_text_callback\n\u001b[0;32m    111\u001b[0m \u001b[39m# run the prediction\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m pp\u001b[39m.\u001b[39;49mllama_generate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ctx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgpt_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_new_text_callback, verbose)\n\u001b[0;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pyllamacpp\\model.py:82\u001b[0m, in \u001b[0;36mModel._call_new_text_callback\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_new_text_callback\u001b[39m(\u001b[39mself\u001b[39m, text) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m    Internal new_segment_callback, it just calls the user's callback with the `Segment` object\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m    :return: None\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mif\u001b[39;00m Model\u001b[39m.\u001b[39m_new_text_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m         Model\u001b[39m.\u001b[39m_new_text_callback(text)\n\u001b[0;32m     84\u001b[0m     \u001b[39m# save res\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cadena_alt2.run(pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='emitted = -100%;+ 6 AH + 2 CO2 avoided (*) = nan;+ 6 AH + million units. = -24%; ;  Tabla=:  + 7 Distr. + nan = Distr.;+ 7 Distr. + CO2 emitted = -34%;+ 7 Distr. + 2 CO2 emitted = -43%;+ 7 Distr. + 2 CO2 avoided (*) = nan;+ 7 Distr. + million units. = -41%; ;', metadata={'source': 'lista_test_2.csv pag90'})]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In this document, CO2 emission is calculated in percentages. The first entry states that -100% of CO2 was emitted, and the last entry states that -41% of CO2 was emitted when 7 Distr. and a million units were used. So, in total, the amount of CO2 emitted was -141%, which is equivalent to 1.41 times the amount of CO2 that would normally be emitted.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPENAI:\n",
    "cadena_OAI.run(\n",
    "    input_documents = similares,\n",
    "    question = pregunta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# GPT4ALL:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cadena_GPT4all\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m      3\u001b[0m     input_documents \u001b[39m=\u001b[39;49m similares,\n\u001b[0;32m      4\u001b[0m     question \u001b[39m=\u001b[39;49m pregunta)  \n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:216\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    218\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but not both. Got args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:56\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m     55\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[1;32m---> 56\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_docs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mother_keys)\n\u001b[0;32m     57\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[0;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:89\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs), {}\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:151\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    138\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:57\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:118\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[0;32m    117\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:62\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list)\n\u001b[1;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(prompts, stop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:107\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m, prompts: List[PromptValue], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    106\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:140\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:137\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:324\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    322\u001b[0m generations \u001b[39m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m--> 324\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    325\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[0;32m    326\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\gpt4all.py:177\u001b[0m, in \u001b[0;36mGPT4All._call\u001b[1;34m(self, prompt, stop)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Call out to GPT4All's generate method.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39m            response = model(prompt, n_predict=55)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    178\u001b[0m         prompt,\n\u001b[0;32m    179\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_params,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m stop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         text \u001b[39m=\u001b[39m enforce_stop_tokens(text, stop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pyllamacpp\\model.py:112\u001b[0m, in \u001b[0;36mModel.generate\u001b[1;34m(self, prompt, n_predict, new_text_callback, verbose, **gpt_params)\u001b[0m\n\u001b[0;32m    109\u001b[0m Model\u001b[39m.\u001b[39m_new_text_callback \u001b[39m=\u001b[39m new_text_callback\n\u001b[0;32m    111\u001b[0m \u001b[39m# run the prediction\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m pp\u001b[39m.\u001b[39;49mllama_generate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ctx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgpt_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_new_text_callback, verbose)\n\u001b[0;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pyllamacpp\\model.py:82\u001b[0m, in \u001b[0;36mModel._call_new_text_callback\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_new_text_callback\u001b[39m(\u001b[39mself\u001b[39m, text) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m    Internal new_segment_callback, it just calls the user's callback with the `Segment` object\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m    :return: None\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mif\u001b[39;00m Model\u001b[39m.\u001b[39m_new_text_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m         Model\u001b[39m.\u001b[39m_new_text_callback(text)\n\u001b[0;32m     84\u001b[0m     \u001b[39m# save res\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GPT4ALL:\n",
    "cadena_GPT4all.run(\n",
    "    input_documents = similares,\n",
    "    question = pregunta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# GPT4ALL con Cadena Alternativa:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m contexto_pregunta \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(i\u001b[39m.\u001b[39mpage_content\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mi\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39msimilares)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m cadena_alt\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m      4\u001b[0m     question \u001b[39m=\u001b[39;49m pregunta,\n\u001b[0;32m      5\u001b[0m     context \u001b[39m=\u001b[39;49m contexto_pregunta)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:216\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    218\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but not both. Got args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:57\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:118\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[0;32m    117\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\chains\\llm.py:62\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list)\n\u001b[1;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(prompts, stop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:107\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m, prompts: List[PromptValue], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    106\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:140\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:137\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\base.py:324\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop)\u001b[0m\n\u001b[0;32m    322\u001b[0m generations \u001b[39m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m--> 324\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    325\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[0;32m    326\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\langchain\\llms\\gpt4all.py:177\u001b[0m, in \u001b[0;36mGPT4All._call\u001b[1;34m(self, prompt, stop)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Call out to GPT4All's generate method.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39m            response = model(prompt, n_predict=55)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    178\u001b[0m         prompt,\n\u001b[0;32m    179\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_params,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m stop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         text \u001b[39m=\u001b[39m enforce_stop_tokens(text, stop)\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pyllamacpp\\model.py:112\u001b[0m, in \u001b[0;36mModel.generate\u001b[1;34m(self, prompt, n_predict, new_text_callback, verbose, **gpt_params)\u001b[0m\n\u001b[0;32m    109\u001b[0m Model\u001b[39m.\u001b[39m_new_text_callback \u001b[39m=\u001b[39m new_text_callback\n\u001b[0;32m    111\u001b[0m \u001b[39m# run the prediction\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m pp\u001b[39m.\u001b[39;49mllama_generate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ctx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgpt_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_new_text_callback, verbose)\n\u001b[0;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres\n",
      "File \u001b[1;32mc:\\Users\\Faji\\anaconda3\\envs\\gdelt\\lib\\site-packages\\pyllamacpp\\model.py:82\u001b[0m, in \u001b[0;36mModel._call_new_text_callback\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_new_text_callback\u001b[39m(\u001b[39mself\u001b[39m, text) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m    Internal new_segment_callback, it just calls the user's callback with the `Segment` object\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m    :return: None\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mif\u001b[39;00m Model\u001b[39m.\u001b[39m_new_text_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m         Model\u001b[39m.\u001b[39m_new_text_callback(text)\n\u001b[0;32m     84\u001b[0m     \u001b[39m# save res\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GPT4ALL con Cadena Alternativa:\n",
    "contexto_pregunta = f\"{' '.join(i.page_content for i in similares)}\"\n",
    "cadena_alt.run(\n",
    "    question = pregunta,\n",
    "    context = contexto_pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexto_pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='REPORT;20;20: 98www.rovi.es', metadata={'source': 'lista_test_2.csv', 'row': 96}),\n",
       " Document(page_content='REPORT;20;20: SHAREHOLDER COMPOSITION;63.11%;Norbel Inversores, S.L.;5.57%;Indumenta Pueri, S.L.;3.043%;T.Rowe Price International Funds, Inc;3.005%;Wellington Management Group, LLP;25.275%;Other;7', metadata={'source': 'lista_test_2.csv', 'row': 5}),\n",
       " Document(page_content='REPORT;20;20: –Profarma;Each year, in the Plan Profarma, the Ministry of Industry, Tourism and Trade and the Ministry ;of Health, Social Services and Equality classify the pharmaceutical Companies in accordance ;with their contribution to the Spanish industrial fabric, taking their investment in technology, ;new manufacturing plants, research efforts, etc. as a reference. In February 2020, the results ;of Plan Profarma 2019 were issued and ROVI obtained the classification of Excellent for the ;fourteenth consecutive year. ;KEY FIGURES;(million euros) 2020 2019 2018 2017;Total revenue 421.1 382.5  304.8 277.4;EBITDA 94.2 60.9 29.5 29.9;Net financial debt 19.8 15.9 -62.8 1.1;Employees 1.419 1.310 1.224 1.191102-7;14; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2020.0 + Total revenue = 421.1; KEY FIGURES + (million euros) + 2020.0 + EBITDA = 94.2; KEY FIGURES + (million euros) + 2020.0 + Net financial debt = 19.8; KEY FIGURES + (million euros) + 2020.0 + Employees = 1.419; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2019.0 + Total revenue = 382.5; KEY FIGURES + (million euros) + 2019.0 + EBITDA = 60.9; KEY FIGURES + (million euros) + 2019.0 + Net financial debt = 15.9; KEY FIGURES + (million euros) + 2019.0 + Employees = 1.31; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2018.0 + Total revenue = 304.8; KEY FIGURES + (million euros) + 2018.0 + EBITDA = 29.5; KEY FIGURES + (million euros) + 2018.0 + Net financial debt = -62.8; KEY FIGURES + (million euros) + 2018.0 + Employees = 1.224; ;  Tabla=KEY FIGURES:  KEY FIGURES + (million euros) + 2017.0 + Total revenue = 277.4; KEY FIGURES + (million euros) + 2017.0 + EBITDA = 29.9; KEY FIGURES + (million euros) + 2017.0 + Net financial debt = 1.1; KEY FIGURES + (million euros) + 2017.0 + Employees = 1.191; ;', metadata={'source': 'lista_test_2.csv', 'row': 12}),\n",
       " Document(page_content='REPORT;20;20: Shareholders have the possibility of receiving ROVI’s financial information automatically ;through an e-mail alert system.  Furthermore, the group provides regular, prompt and ;relevant information on the company, such as presentations and legal documents on ;economic and financial aspects and corporate governance, which may be consulted in the ;Investors and Shareholders section of the corporate website www.rovi.es.;Coinciding with its General Shareholders’ Meeting, ROVI prepares an Integrated Report ;in which it summarises the strategic lines of its work and the activities carried out in ;the preceding year. This document forms part of the Informe Reporta, prepared by the ;consulting company Deva, which rates the reports published by the companies listed on the ;General Index of the Madrid Stock Exchange (IGBM) in accordance with the quality of the ;information they provide. In the 2020 edition of Informe Reporta, ROVI was in 22nd place of ;this ranking, which is formed by 120 companies, maintaining the same position as it held in ;2019.; –Customers;ROVI has a query channel for information requests from both international partners and ;direct customers, patients and professionals: www.bemimed.com.;In the event of a complaint, the company opens an enquiry immediately in order to identify ;the cause and prevent any repetition. Furthermore, there is a contact telephone number and ;the e-mail rovi@rovi.es where queries and complaints may be made.; –Society and environment;As a catalyst in its socioeconomic surroundings and aware of the impact of its activity on ;the environment, ROVI is committed, as an integral part of its day-to-day activity, to the ;protection of the environment, as well as to improving the situation of society in general and ;the different geographical areas  all over the world where it is present with its product or ;plants.;The company’s environmental policy is based on commitments to continuing improvement ;of products and processes, while, at the same time, complying with both legal requirements ;and additional voluntary requirements. In relation to environmental queries, ROVI has a ;corporate procedure through which it manages communications (queries, complaints, etc.) ;related to the environment and occupational health and safety. On the corporate website ;(www.rovi.es), the quality, environmental and occupational health and safety certifications ;held by group companies are available to the public. ;Over recent years, the company has carried out intensive activity to support research and ;promote prevention and knowledge of certain diseases. ROVI allocates part of its resources ;to driving medical and healthcare knowledge forward through contributions to different ;projects and co-operation with higher-education entities, with which it also works to help ;young professionals enter the workplace through scholarships and training. ;27', metadata={'source': 'lista_test_2.csv', 'row': 25})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pregunta = '¿De qué empresa es este informe?'\n",
    "similares = recuperador.get_relevant_documents(pregunta)\n",
    "cadena.run(input_documents = similares, question = pregunta)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdelt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
